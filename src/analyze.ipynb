{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from typing import List, Dict, Union\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from openai import OpenAI\n",
    "from metrics import *\n",
    "from agent import *\n",
    "from prompt import *\n",
    "from scipy.spatial.distance import jensenshannon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re-run for error cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "            api_key = \"empty\",\n",
    "            base_url = \"http://localhost:8000/v1\",\n",
    "            timeout=120.0\n",
    "            )\n",
    "    \n",
    "class Response(BaseModel):\n",
    "    reasoning: str = Field(description=\"Step-by-step explanation of how you interpreted the report to determine the cancer stage.\")\n",
    "    stage: str = Field(description=\"The cancer stage determined from the report.\")\n",
    "    \n",
    "testing_schema = Response.model_json_schema()\n",
    "\n",
    "def test_individual_report(dataset, patient_filename, prompt_method, prompt, stage_type, context):\n",
    "    report = dataset[dataset.patient_filename == patient_filename][\"text\"].values[0]\n",
    "\n",
    "    if context:\n",
    "        formatted_prompt = prompt.format(report=report, context=context)\n",
    "    else:\n",
    "        formatted_prompt = prompt.format(report=report)\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "        messages = messages,\n",
    "        extra_body = {\"guided_json\": testing_schema},\n",
    "        temperature = 0.1)\n",
    "    \n",
    "    response = json.loads(response.choices[0].message.content)\n",
    "\n",
    "    dataset.loc[dataset[\"patient_filename\"] == patient_filename, f'{prompt_method}_{stage_type}_reasoning'] = response[\"reasoning\"]\n",
    "    dataset.loc[dataset[\"patient_filename\"] == patient_filename, f'{prompt_method}_{stage_type}_stage'] = response[\"stage\"]\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "before:  nan\n"
     ]
    },
    {
     "ename": "APITimeoutError",
     "evalue": "Request timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpx/_transports/default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpcore/_sync/connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpcore/_sync/http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpcore/_sync/http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    107\u001b[0m     (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m         trailing_data,\n\u001b[0;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    115\u001b[0m         http_version,\n\u001b[1;32m    116\u001b[0m         status,\n\u001b[1;32m    117\u001b[0m         reason_phrase,\n\u001b[1;32m    118\u001b[0m         headers,\n\u001b[1;32m    119\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpcore/_sync/http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpcore/_sync/http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpcore/_backends/sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv(max_bytes)\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/openai/_base_client.py:978\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 978\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mhandle_request(req)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/httpx/_transports/default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPITimeoutError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(idx) \n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore: \u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatient_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m patient_filename, label_column]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m---> 34\u001b[0m \u001b[43mtest_individual_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mprompt_method\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstage_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mafter: \u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatient_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m patient_filename, label_column]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel: \u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatient_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m patient_filename, stage_type]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[29], line 22\u001b[0m, in \u001b[0;36mtest_individual_report\u001b[0;34m(dataset, patient_filename, prompt_method, prompt, stage_type, context)\u001b[0m\n\u001b[1;32m     19\u001b[0m     formatted_prompt \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mformat(report\u001b[38;5;241m=\u001b[39mreport)\n\u001b[1;32m     21\u001b[0m messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: formatted_prompt}]\n\u001b[0;32m---> 22\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistralai/Mixtral-8x7B-Instruct-v0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mguided_json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_schema\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     30\u001b[0m dataset\u001b[38;5;241m.\u001b[39mloc[dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatient_filename\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m patient_filename, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_reasoning\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreasoning\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/openai/resources/chat/completions.py:646\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, service_tier, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    644\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    645\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 646\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/openai/_base_client.py:1266\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1254\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1262\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1263\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1264\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1265\u001b[0m     )\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/openai/_base_client.py:942\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    935\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    940\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    941\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 942\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/openai/_base_client.py:987\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    984\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/openai/_base_client.py:1079\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/openai/_base_client.py:987\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    984\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 987\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/openai/_base_client.py:1079\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1079\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vllm_env/lib/python3.9/site-packages/openai/_base_client.py:997\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    988\u001b[0m             input_options,\n\u001b[1;32m    989\u001b[0m             cast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    993\u001b[0m             response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    994\u001b[0m         )\n\u001b[1;32m    996\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising timeout error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 997\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APITimeoutError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    999\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAPITimeoutError\u001b[0m: Request timed out."
     ]
    }
   ],
   "source": [
    "with open(\"/home/yl3427/cylab/rag_tnm/src/context.json\", \"r\") as f:\n",
    "    context = json.load(f)\n",
    "\n",
    "rag_raw_t14 = context[\"rag_raw_t14\"]\n",
    "rag_raw_n03 = context[\"rag_raw_n03\"]\n",
    "ltm_zs_t14 = context[\"ltm_zs_t14\"]\n",
    "ltm_zs_n03 = context[\"ltm_zs_n03\"]\n",
    "ltm_rag1_t14 = context[\"ltm_rag1_t14\"]\n",
    "ltm_rag1_n03 = context[\"ltm_rag1_n03\"]\n",
    "ltm_rag2_t14 = context[\"ltm_rag2_t14\"]\n",
    "ltm_rag2_n03 = context[\"ltm_rag2_n03\"]\n",
    "\n",
    "df = pd.read_csv(f\"/home/yl3427/cylab/rag_tnm/rag_result/0929_ltm_rag2.csv\")\n",
    "\n",
    "prompt_method = \"ltm_rag1\" # zscot, rag_raw, ltm_zs, ltm_rag1, ltm_rag2\n",
    "stage_type = \"n\" # t, n\n",
    "context = ltm_rag1_n03\n",
    "\n",
    "# key: f\"{prompt_method}_{stage_type}\"\n",
    "prompt = {\"zscot_t\": zscot_t14, \"zscot_n\": zscot_n03, \n",
    "          \"rag_raw_t\": rag_t14, \"rag_raw_n\": rag_n03, \n",
    "          \"ltm_zs_t\": ltm_t14, \"ltm_zs_n\": ltm_n03, \n",
    "          \"ltm_rag1_t\": ltm_t14, \"ltm_rag1_n\": ltm_n03, \n",
    "          \"ltm_rag2_t\": ltm_t14, \"ltm_rag2_n\": ltm_n03}\n",
    "\n",
    "# T14\n",
    "\n",
    "for idx in range(len(df)):     \n",
    "    patient_filename = df.loc[idx, \"patient_filename\"]\n",
    "    label_column = f'{prompt_method}_{stage_type}_stage'\n",
    "    if not isinstance(df.loc[df[\"patient_filename\"] == patient_filename, label_column].values.item(), str):\n",
    "        print(idx) \n",
    "        print(\"before: \", df.loc[df[\"patient_filename\"] == patient_filename, label_column].values.item())\n",
    "        test_individual_report(df, patient_filename, prompt_method, prompt[f\"{prompt_method}_{stage_type}\"], stage_type, context)\n",
    "        print(\"after: \", df.loc[df[\"patient_filename\"] == patient_filename, label_column].values.item())\n",
    "        print(\"label: \", df.loc[df[\"patient_filename\"] == patient_filename, stage_type].values.item())\n",
    "\n",
    "# df.to_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_t14_dynamic_test_{run}_outof_10runs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_filename', 't', 'text', 'n', 'zscot_t_reasoning',\n",
       "       'zscot_t_stage', 'zscot_n_reasoning', 'zscot_n_stage',\n",
       "       'rag_raw_t_reasoning', 'rag_raw_t_stage', 'rag_raw_n_reasoning',\n",
       "       'rag_raw_n_stage', 'ltm_zs_t_reasoning', 'ltm_zs_t_stage',\n",
       "       'ltm_zs_n_reasoning', 'ltm_zs_n_stage', 'ltm_rag1_t_reasoning',\n",
       "       'ltm_rag1_t_stage', 'ltm_rag1_n_reasoning', 'ltm_rag1_n_stage',\n",
       "       'ltm_rag2_t_reasoning', 'ltm_rag2_t_stage', 'ltm_rag2_n_reasoning',\n",
       "       'ltm_rag2_n_stage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/yl3427/cylab/rag_tnm/rag_result/0929_ltm_rag2.csv\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mt14_calculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzscot_t_stage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(t14_calculate_metrics(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrag_raw_t_stage\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(t14_calculate_metrics(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m'\u001b[39m], df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mltm_zs_t_stage\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverall\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/cylab/rag_tnm/src/metrics.py:15\u001b[0m, in \u001b[0;36mt14_calculate_metrics\u001b[0;34m(true_labels, predictions)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe length of true_labels and predictions must be the same.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pred, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predictions):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mpred\u001b[49m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# raise ValueError(\"All predictions must be non-null strings.\")\u001b[39;00m\n\u001b[1;32m     18\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m true_labels\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(t14_calculate_metrics(df['t'], df['zscot_t_stage'])['overall'])\n",
    "print(t14_calculate_metrics(df['t'], df['rag_raw_t_stage'])['overall'])\n",
    "print(t14_calculate_metrics(df['t'], df['ltm_zs_t_stage'])['overall'])\n",
    "print(t14_calculate_metrics(df['t'], df['ltm_rag1_t_stage'])['overall'])\n",
    "print(t14_calculate_metrics(df['t'], df['ltm_rag2_t_stage'])['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path No.: Date Obtained: (Age: ). Date Received: F. See Addendum/Procedure. SPECIMEN: A:Lymph node, right axilla sentinel node, biopsy. B:Breast, right, lumpectomy. C:Lymph nodes, right axilla, dissection. DIAGNOSIS(ES): A. Lymph node, right axilla sentinel node, biopsy: - Carcinoma in 1 sentinel node following carcinoma of right breast. B. Breast, right, lumpectomy: - Carcinoma, invasive ductal type, moderately-differentiated, with focal micropapillary features,. Nottingham's score 5 (2+2+1). - Carcinoma, intraductal, comedo type with microcalcifications. - Lobular neoplasia, focal, classical type. - Fibrocystic disease, proliferative, with apocrine metaplasia, sclerosing adenosis and. microcalcifications. - Cicatricial fibrosis and organizing granulation tissue with fat necrosis, consistent with previous. biopsy site. - Fibroadenoma, microscopic. C. Lymph nodes, right axilla, dissection: - No evidence of carcinoma in 14 lymph nodes. Date Dictated: CLINICAL INFORMATION: Breast cancer. GROSS DESCRIPTION: The specimen is received in three parts. Part A is received fresh from the operating room for frozen section diagnosis in a container labeled with the patient's. name and \"R sentinel lymph node\". It consists of one firm tan to red lymph node measuring 2.0 x 1.8 X 1,0 cm, The. specimen is serially sectioned. Submitted in toto in three cassettes labeled AFS, A1 and A2. AFS = frozen section, A1. - A2 = remaining tissue,. Part B is received unfixed in a container labeled with the patient's name and \"R breast lumpectomy\". It consists of a. piece of yellow-white fibrofatty tissue measuring 10.5 X 9.0 x 6,0 cm. An ellipse of skin is not present. An X-ray is. received. A localization needle is not noted. A short suture is noted indicating the superior margin and a row of long. sutures are noted indicating the lateral margin. A mass is palpated in the center. The superficial surface is inked yellow. and the deep surface is inked black. The specimen is serially sectioned. On cut section, the mass is tan, firm, poorly. circumscribed and measures 3.2 x 3.0 x 3.0 cm. The mass comes to 0.3 cm of the superficial, 0.5 cm of the deep and. 2.5 cm of the lateral margins. The tissue is composed of 60% fat and 40% intermixed firm tan-white parenchyma. Representative sections are submitted in 29 cassettes labeled B1 - B29. Legend: B1 = mass and closest deep surface,. B2 = mass and closest superficial surface(B1 and B2 = full thickness of mass),. B3 - B8 = mass with adjacent deep margin. B9 - B17 = superficial margin over mass. B18 - B19 = mass. B20 - B21 = superior. B22 - B23 = deep margin in lateral part(closest to mass). B24 - B25 If lateral. B26 - B27 = inferior. B28 - B29 = medial. Part C is received unfixed in a container labeled with the patient's name and \"R axillary lymph node dissection\". It. consists of two pieces of yellow-red fatty tissue measuring 4.0 x 2.7 x 1.0 cm and 10.0 x 7.0 X 1.0 cm. A suture is noted. attached to one end of the larger piece of fatty tissue. Fourteen lymph moves measuring from 0.6 X 0.5 x 0.5 cm. to. 3.5. x 1.5 x 1.0 cm are identified. The lymph nodes are submitted in toto 10 cassettes labeled C1 - C10. Legend: C1 = five intact nodes, C2 - C5 = one bisected node in each cassettes, C6 = one intact node, C7 - C8 = one. large quadrisected node, C9 - C10 = nodes closest to suture(larger node is bisected). INTRAOPERATIVE CONSULTATION: AFS: Metastatic carcinoma in lymph node. Performed by: Resident: interpreted by: Attending: MICROSCOPIC DESCRIPTION: I. TYPE OF SPECIMEN: Right breast, excisional biopsy/lumpectomy. Right axillary node dissection. II. LOCATION OF THE TUMOR: Upper outer quadrant. III. TYPE OF NEOPLASM: Carcinoma, invasive - ductal type NOS with micropapillary features. Histological Grading: Moderately differentiated. (Nuclear grade 2 and Tubular & Glandular differentiation grade 2). Ductal carcinoma in situ, nuclear grade 3, multifocal 10%. intraductal comedo subtype. Necrosis is present within the intraductal subtype. Lobular neoplasia, type A (monomorphic), Focal in 2 of 29 slides. IV. GROSS/MICRO FINAL INVASIVE TUMOR SIZE INTERPRETATION: 3.2 x 3.0 x 3.0 cm. V. BORDERS OF INVASIVE NEOPLASM: III-defined. VI. VASCULAR SPACE INVASION: Present in lymphatics. VII. CALCIFICATION: Present in both malignant and benign areas. VIII. NIPPLE: N/A. IX. SKIN: N/A. X. ADJACENT BREAST TISSUE: Fibroadenoma (size 0,2 cm.). Cystic disease, proliferative. XI. SURGICAL MARGIN: No carcinoma is identified on surgical margins. Tumor distance from closest deep (slide \"B1\") margin: 0.6 cm. XII. AXILLARY LYMPH NODES: TOTAL: 15. HIGH POINT: 2. SENTINEL NODE: 1. XIII. POSITIVE LYMPH NODES: TOTAL: 1. HIGH POINT: 0. SENTINEL NODE: 1. DEGREE OF INVOLVEMENT: Extensive replacement. EXTRANODAL EXTENSION: Present. XIV. PECTORAL MUSCLE: No pectoral muscle identified. This report has been reviewed electronically and signed on. Interpreted by: Attending: The diagnosis was rendered by the attending pathologist. Addendum. ADDENDUM. Slides were reviewed by. The diagnosis rendered is in. agreement with the original diagnosis. This procedure/addenda has been electronically reviewed and signed on. Interpreted by: Attending: Note: Immunochemistry testing performed at. was developed and Its performance characteristics determined by the. These tests were interpreted in conjunction with external positive and internal negative controla, unless otherwise noted It has not been cleared or approved by the US. FDA. This test is used for clinical purposes only, It should not be regarded as Investigational or for research.\n",
      "Path No.: Date Obtained: (Age: ). Date Received: F. SPECIMEN: Breast, right, skin sparing modified radical mastectomy. DIAGNOSIS(ES): Breast, right, skin sparing modified radical mastectomy: Invasive ductal carcinoma, poorly differentiated (Modified Scarff Bloom Richardson Score 3+3+2=8/9),. multifocal, with lymphatic invasion. Metastatic carcinoma in 1/23 axillary lymph nodes (See microscopic description). pT2N1. CLINICAL INFORMATION: Right breast cancer. GROSS DESCRIPTION: The specimen is received unfixed in a container labeled with the patient's name and \"Right breast mastectomy\". It. consists. of. a right modified mastectomy specimen measuring 24,0 X 20,0 x 5.2 cm. A suture is noted indicating the. axillary tail. The overlying skin measures 14.5 X 8.0 cm. The nipple is mobile and everted. An underlying mass is. palpable in the 6 o'clock position. The deep (fascial) margin- is inked black and the remaining margins are inked yellow. The. axillary tissue measures 11.0 X 6,5 x 2.0 cm. Multiple lymph nodes are palpable within it measuring from 0.5 cm to. 1.7 cm in greatest dimension. The lymph nodes are dissected, proceeding from the breast toward the axilla. The. specimen is serially sectioned at closely spaced intervals revealing a firm, poorly circumscribed, white and focally. hemorrhagic. mass measuring 3.5 x 3.0 x 2.0 cm located in the inferior aspect of the specimen (6 o'clock position). The. mass comes to within 0.8 cm of the skin and 3.0 cm of the deep margin. A second firm, well circumscribed mass. measuring 0.7 x 0.5 x 0.5 is also identified located located 0.8 cm from the skin, 2.4 cm from the deep margin and 2,0. cm from the previously described mass, superiorly. The parenchyma superior and lateral to both masses is firm,. lobulated and gritty over an area measuring 4.0 x 3.5 x 2.0 cm. The remaining tissue is composed of a moderate. amount of breast tissue and a moderate amount of yellow fatty tissue. Representative sections are submitted in 37. cassettes labeled A1-A37. Please note: The specimen was placed in formalin at. LEGEND: A1-A3 = Nipple. A4 = Deep margin closest to main mass. A5 = Main mass with closest skin. A6-A8 = Main mass. A9-A10 = Smaller mass. A11 = Smaller mass with closest skin. A12 = Deep margin closest to smaller mass. A13-A18 = Gritty area surrounding masses. A19-A20 = Upper inner quadrant. A21-A22 = Lower inner quadrant. A23-A24 = Lower outer quadrant. A25-A26 = Upper outer quadrant. A27 = Bisected lymph node closest to breast. A28 =3 intact nodes. A29 = 3 intact nodes. A30 = 1 bisected node. A31. = 1 bisected node. A32 = 1 bisected node. A33 = 2 intact nodes. A34 = 4 intact nodes. A35 = 3 intact nodes. A36 = 2 intact nodes. A37 = 1 bisected node at high point. MICROSCOPIC DESCRIPTION: I. TYPE OF SPECIMEN: Right modified radical mastectomy. II. LOCATION OF THE TUMOR: Central (6 o'clock), extending into lower inner and outer quadrants. III. TYPE OF NEOPLASM: Carcinoma, invasive, ductal, with central scar and micropapillary features. Poorly Differentiated, Total score 8. (Tubule Score 3, Nuclear Grade Score 3, Mitotic Score 2). Ductal carcinoma in situ, nuclear grade 3, multifocal 30%. Intraductal papillary subtype. Intraductal micropapillary subtype. Intraductal solid subtype. Intraductal comedo subtype. Necrosis is present within the intraductal carcinoma. Lobular neoplasia is not present. IV. GROSS/MICRO FINAL INVASIVE TUMOR SIZE INTERPRETATION: 3.5 x 3.0 x 2,0 cm. (In addition, separate. foci of invasive carcinoma are seen superior to and lateral to the main mass these have a similar histology; the largest. such focus measures 1.5cm on the slide. VI. VASCULAR SPACE INVASION: Present in lymphatics. VII. CALCIFICATION: Present in malignant areas. VIII,. NIPPLE: Present, uninvolved by cancer. IX. SKIN: Present, uninvolved by cancer. X. ADJACENT BREAST TISSUE: Cystic disease, proliferative with atypia. XI. MARGINS: Negative. XII. AXILLARY LYMPH NODES: XII. AXILLARY LYMPH NODES: TOTAL: 23. HIGH POINT: 1. XIII. POSITIVE LYMPH NODES: XIII. POSITIVE LYMPH NODES: TOTAL: 1. LEVEL I;. 1 (adjacent to breast). EXTRANODAL EXTENSION: Present. XIV. PECTORAL MUSCLE: No pectoral muscle identified. XV. PATHOLOGIC STAGING (pTNM) AJCC 7th Edition: Reflects staging only of the current specimen. Ultimate. staging responsibility rests with the primary physician. pT2: Tumor more than 2.0 cm but not more than 5.0 cm in greatest dimension. pN1a: Metastasis in 1 to 3 axillary lymph nodes (at least 1 tumor deposit greater than 2.0 mm). This report has been reviewed electronically and signed on. Interpreted by: Attending: The diagnosis was rendered by the attending pathologist. Note; Immunochemistry testing performed at. was developed and its performance characteristice determined by the. These tests were interpreted in conjunction with external positive and internal regative controls, unless otherwise noted. It has not been cleared of approved by the US. FDA. This test Is used for clinical purposes only. it should not be regarded as investigational or for research.\n",
      "Procedure: Left radical mastectomy. Preoperative diagnosis: CARCINOMA OF THE LEFT BREAST. Postoperative diagnosis: SEE MICROSCOPIC DIAGNOSIS BELOW. Specimen(s): 1. LEFT BREAST 2. LEFT AXILLARY CONTENTS. Diagnosis: 1. LEFT BREAST: Infiltrating lobular carcinoma grade 2. Tumor is 2.8 x 3.5 x 3.0 cm in dimensions. Vascular invasion is not present. 2. LEFT AXILLARY LYMPH NODES: Four (out of fourteen) axillary lymph nodes are positive for metastatic carcinoma. Gross description: 1. LEFT BREAST: Received fresh, is a left breast measured 30.0 x 27.0 x 9.0 cm in dimensions with an axillary fat,. en bloc. The firm white-gray tumor 2.8 x 3.5 x 3.0 cm in dimensions is present in the outer. quadrants. 2. LEFT AXILLARY CONTENTS: Within the axillary fat there are fourteen lymph nodes ranging from 0.2 to 2.0 cm in greatest. dimension.\n",
      "Gender: Female. Color: White. Origin: Nature of material: Breast. Biopsy number: Gross description: Received one piece of fibrofatty tissue measuring 2.2 x1.2 X 0.4 cm marked with shorts suture. On slicing in the central part is a white and firm area measuring 0.4 cm in the largest. diameter. Microscopy. Dispensable description. Conclusions: Right breast wide excision: Invasive lobular carcinoma, grade 1;. Immunohistochemistry: e-cadherin: negative;. ER: positive in 70%;. PgR: positive in 20%;. HER2: negative (score 1+). PARTICIPANTS OF APPRAISAL REPORT. Issuer. - Reviewer. - Reviewer.\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    if idx == 4:\n",
    "        break\n",
    "    report = row['text']\n",
    "    print(report)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>zscot_t_stage</th>\n",
       "      <th>rag_raw_t_stage</th>\n",
       "      <th>ltm_zs_t_stage</th>\n",
       "      <th>ltm_rag1_t_stage</th>\n",
       "      <th>ltm_rag2_t_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>T2</td>\n",
       "      <td>T3</td>\n",
       "      <td>T2</td>\n",
       "      <td>T3</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>T2</td>\n",
       "      <td>T1</td>\n",
       "      <td>T3</td>\n",
       "      <td>T3</td>\n",
       "      <td>T1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>T2</td>\n",
       "      <td>T1c</td>\n",
       "      <td>T3</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>T2</td>\n",
       "      <td>T3</td>\n",
       "      <td>T2</td>\n",
       "      <td>T3</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>3</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0</td>\n",
       "      <td>T2</td>\n",
       "      <td>T1c</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T3</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T1</td>\n",
       "      <td>T2</td>\n",
       "      <td>T3</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "      <td>T2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     t zscot_t_stage rag_raw_t_stage ltm_zs_t_stage ltm_rag1_t_stage  \\\n",
       "0    1            T2              T3             T2               T3   \n",
       "1    1            T2              T2             T2               T2   \n",
       "2    1            T2              T1             T3               T3   \n",
       "3    1            T2             T1c             T3               T2   \n",
       "4    1            T2              T3             T2               T3   \n",
       "..  ..           ...             ...            ...              ...   \n",
       "795  3            T2              T2             T2               T2   \n",
       "796  0            T2             T1c             T2               T2   \n",
       "797  2            T2              T2             T2               T3   \n",
       "798  2            T2              T1             T2               T3   \n",
       "799  0            T2              T2             T2               T2   \n",
       "\n",
       "    ltm_rag2_t_stage  \n",
       "0                 T2  \n",
       "1                 T2  \n",
       "2                T1c  \n",
       "3                 T2  \n",
       "4                 T2  \n",
       "..               ...  \n",
       "795               T2  \n",
       "796               T2  \n",
       "797               T2  \n",
       "798               T2  \n",
       "799               T2  \n",
       "\n",
       "[800 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['t', 'zscot_t_stage', 'rag_raw_t_stage', 'ltm_zs_t_stage', 'ltm_rag1_t_stage', 'ltm_rag2_t_stage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t14_calculate_metrics(df['t'], df['cmem_t_ans_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n03_calculate_metrics(n_zscot_df['n'], n_zscot_df['zs_n_ans_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n03_calculate_metrics(df['n'], df['cmem_n_ans_str'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter data for Qualitative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/t14_memory_dataset0.csv\")\n",
    "memory_dict_t = {}\n",
    "for idx, row in t_train_df.iterrows():\n",
    "    memory_dict_t[f\"{idx+1}\"] = row['cmem_t_memory_str']\n",
    "\n",
    "\n",
    "for i in ['10', '20', '30', '40', '50', '60', '70', '80', '90', '100']:\n",
    "    print(f\"Memory at {i}\")\n",
    "    print(memory_dict_t[i])\n",
    "    print()\n",
    "    print(len(memory_dict_t[i]))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_groundtruth_issue = {\"TCGA-B6-A0IE.DFCA9C6E-710E-4645-9CFC-A908AAD583F3\", \"TCGA-JL-A3YX.25782EF0-8786-446E-ADBA-21F489844237\", \n",
    "                       \"TCGA-B6-A0IE.DFCA9C6E-710E-4645-9CFC-A908AAD583F3\",\"TCGA-BH-A208.4F943D12-E769-45F3-86BE-75193786DD4E\", \n",
    "                       \"TCGA-AO-A0J9.1E3F3136-6D86-4470-85AA-55B11C9E24CD\", \"TCGA-BH-A1FM.DA6A0EC9-6E20-4E4A-9B7F-A32EFF7627AD\", \n",
    "                       \"TCGA-D8-A1JS.0EA57ABF-E3DA-4862-BAB8-A6E36408AC42\", \"TCGA-JL-A3YX.25782EF0-8786-446E-ADBA-21F489844237\",\n",
    "                       \"TCGA-BH-A1FM.DA6A0EC9-6E20-4E4A-9B7F-A32EFF7627AD\"}\n",
    "t_groundtruth_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_t14_dynamic_test_0_outof_10runs_verified_wm_for_40.csv\").sort_values(by=\"patient_filename\")\n",
    "t_zscot_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zscot_test_800_verified_wm.csv\").sort_values(by=\"patient_filename\")\n",
    "\n",
    "split_ids = t_test_df.patient_filename\n",
    "t_zscot_df = t_zscot_df[t_zscot_df.patient_filename.isin(split_ids)]\n",
    "for memory_patient, zs_patient in zip(t_test_df.patient_filename, t_zscot_df.patient_filename):\n",
    "    assert memory_patient == zs_patient\n",
    "\n",
    "# output_dir = \"/secure/shared_data/studio_label/zscot_error_t_verified\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "ids_set = set()\n",
    "for idx, (filename, label, memory_ans, zscot_ans, memory_rsn, zscot_rsn, memory_feedback, zscot_feedback, memory_final_stage, zscot_final_stage) in enumerate(zip(t_test_df.patient_filename, t_test_df.t, t_test_df.cmem_t_40reports_ans_str, t_zscot_df.zs_t_ans_str, t_test_df.cmem_t_40reasoning, t_zscot_df.zs_t_reasoning, t_test_df.t_feedback, t_zscot_df.t_feedback, t_test_df.t_final_stage, t_zscot_df.t_final_stage)):\n",
    "    if filename in t_groundtruth_issue:\n",
    "        continue\n",
    "    # if (f\"T{label+1}\" in zs_ans.upper()) and (f\"T{label+1}\" in memory_ans.upper()): # cases where both are correct\n",
    "    if (f\"T{label+1}\" not in zscot_ans.upper()) and (f\"T{label+1}\" in memory_ans.upper()): # cases where only memory was correct\n",
    "    # if (f\"T{label+1}\" in zscot_ans.upper()) and (f\"T{label+1}\" not in memory_ans.upper()): # cases where only zs was correct\n",
    "    # if (f\"T{label+1}\" not in zscot_ans.upper()) and (f\"T{label+1}\" not in memory_ans.upper()): # cases where both were wrong\n",
    "        ids_set.add(filename)\n",
    "        data = {\n",
    "            \"data\": {\n",
    "                \"humanMachineDialogue\": [\n",
    "                    {\"author\": \"Patient filename\", \"text\": filename},\n",
    "                    {\"author\": \"Memory Reasoning\", \"text\": memory_rsn},\n",
    "                    {\"author\": \"ZS Reasoning\", \"text\": zscot_rsn}, \n",
    "                    {\"author\": \"Answer\", \"text\": f\"T{label+1}\"},\n",
    "                    {\"author\": \"Memory Answer\", \"text\": memory_ans},\n",
    "                    {\"author\": \"ZS Answer\", \"text\": zscot_ans},\n",
    "                    {\"author\": \"Memory Feedback\", \"text\": memory_feedback},\n",
    "                    {\"author\": \"ZS Feedback\", \"text\": zscot_feedback},\n",
    "                    {\"author\": \"Memory Final Answer\", \"text\": memory_final_stage},\n",
    "                    {\"author\": \"ZS Final Answer\", \"text\": zscot_final_stage} \n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        print(idx)\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][3])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][4])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][5])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][6])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][7])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][8])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][9])\n",
    "        print(\"--------------------------\")\n",
    "        \n",
    "        # file_name = f\"t3_{idx}.json\"\n",
    "        # file_path = os.path.join(output_dir, file_name)\n",
    "        # with open(file_path, 'w') as json_file:\n",
    "        #     json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEPA_T1 = 0\n",
    "KEPA_T2 = 0\n",
    "KEPA_T3 = 0\n",
    "KEPA_T4 = 0\n",
    "ZSCOT_T1 = 0\n",
    "ZSCOT_T2 = 0\n",
    "ZSCOT_T3 = 0\n",
    "ZSCOT_T4 = 0\n",
    "GT_T1 = 0\n",
    "GT_T2 = 0\n",
    "GT_T3 = 0\n",
    "GT_T4 = 0\n",
    "\n",
    "run_lst = [0, 1, 2, 3, 4, 5, 6, 8]\n",
    "for run in run_lst:\n",
    "    # print(f\"Run {run}, memory 40\")\n",
    "    t_test_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_t14_dynamic_test_{run}_outof_10runs.csv\").sort_values(by=\"patient_filename\")\n",
    "    t_zs_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zs_test_800.csv\").sort_values(by=\"patient_filename\")\n",
    "    t_zscot_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zscot_test_800.csv\").sort_values(by=\"patient_filename\")\n",
    "\n",
    "    split_ids = t_test_df.patient_filename\n",
    "    t_zs_df = t_zs_df[t_zs_df.patient_filename.isin(split_ids)]\n",
    "    t_zscot_df = t_zscot_df[t_zscot_df.patient_filename.isin(split_ids)]\n",
    "    for memory_patient, zs_patient, zscot_patient in zip(t_test_df.patient_filename, t_zs_df.patient_filename, t_zscot_df.patient_filename):\n",
    "        assert memory_patient == zs_patient and memory_patient == zscot_patient\n",
    "\n",
    "    ids_set = set()\n",
    "    label_dict = {\"T1\": set(), \"T2\": set(), \"T3\": set(), \"T4\": set()}\n",
    "    memory_pred_dict = {\"T1\": set(), \"T2\": set(), \"T3\": set(), \"T4\": set()}\n",
    "    memory_correct_dict = {\"T1\": set(), \"T2\": set(), \"T3\": set(), \"T4\": set()}\n",
    "    zs_pred_dict = {\"T1\": set(), \"T2\": set(), \"T3\": set(), \"T4\": set()}\n",
    "    zs_correct_dict = {\"T1\": set(), \"T2\": set(), \"T3\": set(), \"T4\": set()}\n",
    "    zscot_pred_dict = {\"T1\": set(), \"T2\": set(), \"T3\": set(), \"T4\": set()}\n",
    "    zscot_correct_dict = {\"T1\": set(), \"T2\": set(), \"T3\": set(), \"T4\": set()}\n",
    "\n",
    "    three_common_dict = {\"T1\": set(), \"T2\": set(), \"T3\": set(), \"T4\": set()}\n",
    "    both_same_pred_but_wrong_answer_dict = {\"T1\": set(), \"T2\": set(), \"T3\": set(), \"T4\": set()} # each key represents pred\n",
    "    neither_correct_dict = {\"T1\": set(), \"T2\": set(), \"T3\": set(), \"T4\": set()} # each key represents label\n",
    "    for idx, (filename, label, memory_ans, zs_ans, zscot_ans) in enumerate(zip(t_test_df.patient_filename, t_test_df.t, t_test_df.cmem_t_40reports_ans_str, t_zs_df.zs_t_ans_str, t_zscot_df.zs_t_ans_str)):\n",
    "        if f\"T{label+1}\" == \"T1\":\n",
    "            label_dict[\"T1\"].add(filename)\n",
    "            if f\"T{label+1}\" in zscot_ans.upper() and f\"T{label+1}\" in memory_ans.upper():\n",
    "                three_common_dict[\"T1\"].add(filename)\n",
    "            elif f\"T{label+1}\" not in zscot_ans.upper() and f\"T{label+1}\" not in memory_ans.upper():\n",
    "                neither_correct_dict[\"T1\"].add(filename)\n",
    "        if f\"T{label+1}\" == \"T2\":\n",
    "            label_dict[\"T2\"].add(filename)\n",
    "            if f\"T{label+1}\" in zscot_ans.upper() and f\"T{label+1}\" in memory_ans.upper():\n",
    "                three_common_dict[\"T2\"].add(filename)\n",
    "            elif f\"T{label+1}\" not in zscot_ans.upper() and f\"T{label+1}\" not in memory_ans.upper():\n",
    "                neither_correct_dict[\"T2\"].add(filename)\n",
    "        if f\"T{label+1}\" == \"T3\":\n",
    "            label_dict[\"T3\"].add(filename)\n",
    "            if f\"T{label+1}\" in zscot_ans.upper() and f\"T{label+1}\" in memory_ans.upper():\n",
    "                three_common_dict[\"T3\"].add(filename)\n",
    "            elif f\"T{label+1}\" not in zscot_ans.upper() and f\"T{label+1}\" not in memory_ans.upper():\n",
    "                neither_correct_dict[\"T3\"].add(filename)\n",
    "        if f\"T{label+1}\" == \"T4\":\n",
    "            label_dict[\"T4\"].add(filename)\n",
    "            if f\"T{label+1}\" in zscot_ans.upper() and f\"T{label+1}\" in memory_ans.upper():\n",
    "                three_common_dict[\"T4\"].add(filename)\n",
    "            elif f\"T{label+1}\" not in zscot_ans.upper() and f\"T{label+1}\" not in memory_ans.upper():\n",
    "                neither_correct_dict[\"T4\"].add(filename)\n",
    "        # if (f\"T{label+1}\" in zs_ans.upper()) and (f\"T{label+1}\" in memory_ans.upper()): # cases where both are correct\n",
    "        # if (f\"T{label+1}\" not in zs_ans.upper()) and (f\"T{label+1}\" in memory_ans.upper()): # cases where only memory was correct\n",
    "        # if (f\"T{label+1}\" in zs_ans.upper()) and (f\"T{label+1}\" not in memory_ans.upper()): # cases where only zs was correct\n",
    "        # if (f\"T{label+1}\" not in zs_ans.upper()) and (f\"T{label+1}\" not in memory_ans.upper()): # cases where both were wrong\n",
    "        if \"T1\" in memory_ans.upper():\n",
    "            memory_pred_dict[\"T1\"].add(filename)\n",
    "            if \"T1\" == f\"T{label+1}\":\n",
    "                memory_correct_dict[\"T1\"].add(filename)\n",
    "        if \"T2\" in memory_ans.upper():\n",
    "            memory_pred_dict[\"T2\"].add(filename)\n",
    "            if \"T2\" == f\"T{label+1}\":\n",
    "                memory_correct_dict[\"T2\"].add(filename)\n",
    "        if \"T3\" in memory_ans.upper():\n",
    "            memory_pred_dict[\"T3\"].add(filename)\n",
    "            if \"T3\" == f\"T{label+1}\":\n",
    "                memory_correct_dict[\"T3\"].add(filename)\n",
    "        if \"T4\" in memory_ans.upper():\n",
    "            memory_pred_dict[\"T4\"].add(filename)\n",
    "            if \"T4\" == f\"T{label+1}\":\n",
    "                memory_correct_dict[\"T4\"].add(filename)\n",
    "        if \"T1\" in zs_ans.upper():\n",
    "            zs_pred_dict[\"T1\"].add(filename)\n",
    "            if \"T1\" == f\"T{label+1}\":\n",
    "                zs_correct_dict[\"T1\"].add(filename)\n",
    "        if \"T2\" in zs_ans.upper():\n",
    "            zs_pred_dict[\"T2\"].add(filename)\n",
    "            if \"T2\" == f\"T{label+1}\":\n",
    "                zs_correct_dict[\"T2\"].add(filename)\n",
    "        if \"T3\" in zs_ans.upper():\n",
    "            zs_pred_dict[\"T3\"].add(filename)\n",
    "            if \"T3\" == f\"T{label+1}\":\n",
    "                zs_correct_dict[\"T3\"].add(filename)\n",
    "        if \"T4\" in zs_ans.upper():\n",
    "            zs_pred_dict[\"T4\"].add(filename)\n",
    "            if \"T4\" == f\"T{label+1}\":\n",
    "                zs_correct_dict[\"T4\"].add(filename)\n",
    "        if \"T1\" in zscot_ans.upper():\n",
    "            zscot_pred_dict[\"T1\"].add(filename)\n",
    "            if \"T1\" == f\"T{label+1}\":\n",
    "                zscot_correct_dict[\"T1\"].add(filename)\n",
    "        if \"T2\" in zscot_ans.upper():\n",
    "            zscot_pred_dict[\"T2\"].add(filename)\n",
    "            if \"T2\" == f\"T{label+1}\":\n",
    "                zscot_correct_dict[\"T2\"].add(filename)\n",
    "        if \"T3\" in zscot_ans.upper():\n",
    "            zscot_pred_dict[\"T3\"].add(filename)\n",
    "            if \"T3\" == f\"T{label+1}\":\n",
    "                zscot_correct_dict[\"T3\"].add(filename)\n",
    "        if \"T4\" in zscot_ans.upper():\n",
    "            zscot_pred_dict[\"T4\"].add(filename)\n",
    "            if \"T4\" == f\"T{label+1}\":\n",
    "                zscot_correct_dict[\"T4\"].add(filename)\n",
    "        if \"T1\" in memory_ans.upper() and \"T1\" in zscot_ans.upper() and \"T1\" != f\"T{label+1}\":\n",
    "            both_same_pred_but_wrong_answer_dict[\"T1\"].add(filename)\n",
    "        if \"T2\" in memory_ans.upper() and \"T2\" in zscot_ans.upper() and \"T2\" != f\"T{label+1}\":\n",
    "            both_same_pred_but_wrong_answer_dict[\"T2\"].add(filename)\n",
    "        if \"T3\" in memory_ans.upper() and \"T3\" in zscot_ans.upper() and \"T3\" != f\"T{label+1}\":\n",
    "            both_same_pred_but_wrong_answer_dict[\"T3\"].add(filename)\n",
    "        if \"T4\" in memory_ans.upper() and \"T4\" in zscot_ans.upper() and \"T4\" != f\"T{label+1}\":\n",
    "            both_same_pred_but_wrong_answer_dict[\"T4\"].add(filename)\n",
    "            # ids_set.add(filename)\n",
    "          \n",
    "    df1 = pd.DataFrame(\n",
    "        {\n",
    "            \"T1\": [f'{len(memory_pred_dict[\"T1\"])} pred ({len(memory_correct_dict[\"T1\"])} correct)', f'{len(zs_pred_dict[\"T1\"])} pred ({len(zs_correct_dict[\"T1\"])} correct)', f'{len(zscot_pred_dict[\"T1\"])} pred ({len(zscot_correct_dict[\"T1\"])} correct)', f'{len(label_dict[\"T1\"])}'],\n",
    "            \"T2\": [f'{len(memory_pred_dict[\"T2\"])} pred ({len(memory_correct_dict[\"T2\"])} correct)', f'{len(zs_pred_dict[\"T2\"])} pred ({len(zs_correct_dict[\"T2\"])} correct)', f'{len(zscot_pred_dict[\"T2\"])} pred ({len(zscot_correct_dict[\"T2\"])} correct)', f'{len(label_dict[\"T2\"])}'],\n",
    "            \"T3\": [f'{len(memory_pred_dict[\"T3\"])} pred ({len(memory_correct_dict[\"T3\"])} correct)', f'{len(zs_pred_dict[\"T3\"])} pred ({len(zs_correct_dict[\"T3\"])} correct)', f'{len(zscot_pred_dict[\"T3\"])} pred ({len(zscot_correct_dict[\"T3\"])} correct)', f'{len(label_dict[\"T3\"])}'],\n",
    "            \"T4\": [f'{len(memory_pred_dict[\"T4\"])} pred ({len(memory_correct_dict[\"T4\"])} correct)', f'{len(zs_pred_dict[\"T4\"])} pred ({len(zs_correct_dict[\"T4\"])} correct)', f'{len(zscot_pred_dict[\"T4\"])} pred ({len(zscot_correct_dict[\"T4\"])} correct)', f'{len(label_dict[\"T4\"])}']\n",
    "        },\n",
    "        index=[\"KEPA\", \"ZS\", \"ZSCOT\", \"Ground Truth\"]\n",
    "    )\n",
    "    print(f\"{len(memory_pred_dict['T1'])}, {len(memory_pred_dict['T2'])}, {len(memory_pred_dict['T3'])}, {len(memory_pred_dict['T4'])}\", end=\"\\t\")\n",
    "    print(f\"{len(zs_pred_dict['T1'])}, {len(zs_pred_dict['T2'])}, {len(zs_pred_dict['T3'])}, {len(zs_pred_dict['T4'])}\", end=\"\\t\")\n",
    "    print(f\"{len(zscot_pred_dict['T1'])}, {len(zscot_pred_dict['T2'])}, {len(zscot_pred_dict['T3'])}, {len(zscot_pred_dict['T4'])}\", end=\"\\t\")\n",
    "    print(f\"{len(label_dict['T1'])}, {len(label_dict['T2'])}, {len(label_dict['T3'])}, {len(label_dict['T4'])}\")\n",
    "    KEPA_T1 += len(memory_pred_dict[\"T1\"])\n",
    "    KEPA_T2 += len(memory_pred_dict[\"T2\"])\n",
    "    KEPA_T3 += len(memory_pred_dict[\"T3\"])\n",
    "    KEPA_T4 += len(memory_pred_dict[\"T4\"])\n",
    "    ZSCOT_T1 += len(zscot_pred_dict[\"T1\"])\n",
    "    ZSCOT_T2 += len(zscot_pred_dict[\"T2\"])\n",
    "    ZSCOT_T3 += len(zscot_pred_dict[\"T3\"])\n",
    "    ZSCOT_T4 += len(zscot_pred_dict[\"T4\"])\n",
    "    GT_T1 += len(label_dict[\"T1\"])\n",
    "    GT_T2 += len(label_dict[\"T2\"])\n",
    "    GT_T3 += len(label_dict[\"T3\"])\n",
    "    GT_T4 += len(label_dict[\"T4\"])\n",
    "    # display(df1.transpose())\n",
    "    memory_pv = np.array([len(memory_pred_dict[\"T1\"]), len(memory_pred_dict[\"T2\"]), len(memory_pred_dict[\"T3\"]), len(memory_pred_dict[\"T4\"])]) / (len(memory_pred_dict[\"T1\"]) + len(memory_pred_dict[\"T2\"]) + len(memory_pred_dict[\"T3\"]) + len(memory_pred_dict[\"T4\"]))\n",
    "    zs_pv = np.array([len(zs_pred_dict[\"T1\"]), len(zs_pred_dict[\"T2\"]), len(zs_pred_dict[\"T3\"]), len(zs_pred_dict[\"T4\"])]) / (len(zs_pred_dict[\"T1\"]) + len(zs_pred_dict[\"T2\"]) + len(zs_pred_dict[\"T3\"]) + len(zs_pred_dict[\"T4\"]))\n",
    "    zscot_pv = np.array([len(zscot_pred_dict[\"T1\"]), len(zscot_pred_dict[\"T2\"]), len(zscot_pred_dict[\"T3\"]), len(zscot_pred_dict[\"T4\"])]) / (len(zscot_pred_dict[\"T1\"]) + len(zscot_pred_dict[\"T2\"]) + len(zscot_pred_dict[\"T3\"]) + len(zscot_pred_dict[\"T4\"]))\n",
    "    gt_pv = np.array([len(label_dict[\"T1\"]), len(label_dict[\"T2\"]), len(label_dict[\"T3\"]), len(label_dict[\"T4\"])]) / (len(label_dict[\"T1\"]) + len(label_dict[\"T2\"]) + len(label_dict[\"T3\"]) + len(label_dict[\"T4\"]))\n",
    "    # print(memory_pv, zscot_pv, gt_pv)\n",
    "    # print(\"Jensen-Shannon distance between kepa and ground truth: \" ,jensenshannon(memory_pv, gt_pv))\n",
    "    # print(\"Jensen-Shannon distance between zs and ground truth: \" ,jensenshannon(zs_pv, gt_pv))\n",
    "    # print(\"Jensen-Shannon distance between zscot and ground truth: \" ,jensenshannon(zscot_pv, gt_pv))\n",
    "                                                                                                                                        \n",
    "    df2 = pd.DataFrame(\n",
    "        {\n",
    "            \"T1\": [f'{len(three_common_dict[\"T1\"])}', f'{len(memory_pred_dict[\"T1\"])}', f'{len(zscot_pred_dict[\"T1\"])}', f'{len(both_same_pred_but_wrong_answer_dict[\"T1\"])}'],\n",
    "            \"T2\": [f'{len(three_common_dict[\"T2\"])}', f'{len(memory_pred_dict[\"T2\"])}', f'{len(zscot_pred_dict[\"T2\"])}', f'{len(both_same_pred_but_wrong_answer_dict[\"T2\"])}'],\n",
    "            \"T3\": [f'{len(three_common_dict[\"T3\"])}', f'{len(memory_pred_dict[\"T3\"])}', f'{len(zscot_pred_dict[\"T3\"])}', f'{len(both_same_pred_but_wrong_answer_dict[\"T3\"])}'],\n",
    "            \"T4\": [f'{len(three_common_dict[\"T4\"])}', f'{len(memory_pred_dict[\"T4\"])}', f'{len(zscot_pred_dict[\"T4\"])}', f'{len(both_same_pred_but_wrong_answer_dict[\"T4\"])}']\n",
    "        },  \n",
    "        index=[\"3 common\", \"KEPA\", \"ZSCOT\", \"Both same pred but wrong answer\"]         \n",
    "    )\n",
    "    # display(df2.transpose())\n",
    " \n",
    "\n",
    "# print(\"Total\")\n",
    "# df3 = pd.DataFrame(\n",
    "#     {\n",
    "#         \"T1\": [f'{KEPA_T1/len(run_lst)}', f'{ZSCOT_T1/len(run_lst)}', f'{GT_T1/len(run_lst)}'],\n",
    "#         \"T2\": [f'{KEPA_T2/len(run_lst)}', f'{ZSCOT_T2/len(run_lst)}', f'{GT_T2/len(run_lst)}'],\n",
    "#         \"T3\": [f'{KEPA_T3/len(run_lst)}', f'{ZSCOT_T3/len(run_lst)}', f'{GT_T3/len(run_lst)}'],\n",
    "#         \"T4\": [f'{KEPA_T4/len(run_lst)}', f'{ZSCOT_T4/len(run_lst)}', f'{GT_T4/len(run_lst)}']\n",
    "#     },\n",
    "#     index=[\"KEPA\", \"ZSCOT\", \"Ground Truth\"]\n",
    "# )\n",
    "# display(df3.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(memory_pred_dict['T3'] - three_common_dict[\"T3\"] - both_same_pred_but_wrong_answer_dict[\"T3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KEPA\")\n",
    "for k, v in memory_pred_dict.items():\n",
    "    print(f\"{k}: total {len(v)} -> {len(memory_correct_dict[k])} correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ZSCOT\")\n",
    "for k, v in zscot_pred_dict.items():\n",
    "    print(f\"{k}: total {len(v)} -> {len(zscot_correct_dict[k])} correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/n03_memory_dataset1.csv\")\n",
    "memory_dict_n = {}\n",
    "for idx, row in n_train_df.iterrows():\n",
    "    memory_dict_n[f\"{idx+1}\"] = row['cmem_n_memory_str']\n",
    "\n",
    "\n",
    "# for i in ['10', '20', '30', '40', '50', '60', '70', '80', '90', '100']:\n",
    "#     print(f\"Memory at {i}\")\n",
    "#     print(memory_dict_n[i])\n",
    "#     print()\n",
    "#     print(len(memory_dict_n[i]))\n",
    "#     print(\"--------------------------------------------------\")\n",
    "\n",
    "print(memory_dict_n['40'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groundtruth_issue = {\"TCGA-BH-A1FJ.8169BE67-03C8-4F4D-9A60-200705B795AE\", \"TCGA-BH-A6R9.1DB8FAFB-FC4A-4401-8316-30FB5352335D\",\n",
    "                       \"TCGA-E9-A1QZ.864BB34A-1008-480C-A3B5-A2C616E95C49\", \"TCGA-A8-A06Z.956F45E5-A8C6-4A4A-9D1F-D31912180584\",\n",
    "                       \"TCGA-B6-A0IK.3A38A97C-2CBB-4802-9528-A4BBD62AEA4A\", \"TCGA-B6-A0WV.506BFD3B-240B-440E-B7A0-E596FC0B7F72\",\n",
    "                       \"TCGA-E9-A3X8.00058FFD-35E6-4891-8B01-DAB3AE9EBF78\", \"TCGA-GM-A2DA.F3CD8E6E-B02F-4D5D-B895-6DF063F61603\", \n",
    "                       \"TCGA-B6-A0IH.12C64846-1CB3-42E4-B307-54C7AD12F530\", \"TCGA-B6-A0WW.F05F5886-DC5D-4685-B2BF-57A68A0BB7B9\", \n",
    "                       \"TCGA-B6-A0X1.D792031E-2CCE-4341-B3B3-C7D1D84F8F6B\", \"TCGA-GM-A2DA.F3CD8E6E-B02F-4D5D-B895-6DF063F61603\",\n",
    "                       \"TCGA-B6-A1KN.72996825-1FFA-4C51-8DB0-DA74BCB595EB\"}\n",
    "n_groundtruth_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_n03_dynamic_test_1_outof_10runs_numerical_verified_for_40.csv\").sort_values(by=\"patient_filename\")\n",
    "n_zscot_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zscot_test_800_numerical_verified.csv\").sort_values(by=\"patient_filename\")\n",
    "\n",
    "split_ids = n_test_df.patient_filename\n",
    "n_zscot_df = n_zscot_df[n_zscot_df.patient_filename.isin(split_ids)]\n",
    "for memory_patient, zs_patient in zip(n_test_df.patient_filename, n_zscot_df.patient_filename):\n",
    "    assert memory_patient == zs_patient\n",
    "\n",
    "# output_dir = \"/secure/shared_data/studio_label/n3\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "ids_set = set()\n",
    "for idx, (filename, label, memory_ans, zscot_ans, memory_rsn, zscot_rsn, memory_feedback, zscot_feedback, memory_final_stage, zscot_final_stage) in enumerate(zip(n_test_df.patient_filename, n_test_df.n, n_test_df[f\"cmem_n_40reports_ans_str\"], n_zscot_df.zs_n_ans_str, n_test_df[f\"cmem_n_40reasoning\"], n_zscot_df.zs_n_reasoning, n_test_df.n_feedback, n_zscot_df.n_feedback, n_test_df.n_final_stage, n_zscot_df.n_final_stage)):\n",
    "    memory_ans = memory_ans.upper().replace(\"NO\", \"N0\").replace(\"NL\", \"N1\")\n",
    "    zscot_ans = zscot_ans.upper().replace(\"NO\", \"N0\").replace(\"NL\", \"N1\")\n",
    "    if filename in n_groundtruth_issue:\n",
    "        continue\n",
    "    # if (f\"N{label}\" in zscot_ans) and (f\"N{label}\" in memory_ans): # cases where both are correct\n",
    "    # if (f\"N{label}\" not in zscot_ans) and (f\"N{label}\" in memory_ans): # cases where only memory was correct\n",
    "    if (f\"N{label}\" in zscot_ans) and (f\"N{label}\" not in memory_ans): # cases where only zs was correct\n",
    "    # if (f\"N{label}\" not in zscot_ans) and (f\"N{label}\" not in memory_ans): # cases where both were wrong\n",
    "        ids_set.add(filename)\n",
    "        data = {\n",
    "            \"data\": {\n",
    "                \"humanMachineDialogue\": [\n",
    "                    {\"author\": \"Patient filename\", \"text\": filename},\n",
    "                    {\"author\": \"Memory Reasoning\", \"text\": memory_rsn},\n",
    "                    {\"author\": \"ZS Reasoning\", \"text\": zscot_rsn}, \n",
    "                    {\"author\": \"Answer\", \"text\": f\"N{label}\"},\n",
    "                    {\"author\": \"Memory Answer\", \"text\": memory_ans},\n",
    "                    {\"author\": \"ZS Answer\", \"text\": zscot_ans},\n",
    "                    {\"author\": \"Memory Feedback\", \"text\": memory_feedback},\n",
    "                    {\"author\": \"ZS Feedback\", \"text\": zscot_feedback},\n",
    "                    {\"author\": \"Memory Final Answer\", \"text\": memory_final_stage},\n",
    "                    {\"author\": \"ZS Final Answer\", \"text\": zscot_final_stage}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        print(idx)\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][3])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][4])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][5])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][6])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][7])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][8])\n",
    "        print(data[\"data\"][\"humanMachineDialogue\"][9])\n",
    "        print(\"--------------------------\")   \n",
    "        \n",
    "        # file_name = f\"n3_{idx}.json\"\n",
    "        # file_path = os.path.join(output_dir, file_name)\n",
    "        # with open(file_path, 'w') as json_file:\n",
    "        #     json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEPA_N0 = 0\n",
    "KEPA_N1 = 0\n",
    "KEPA_N2 = 0\n",
    "KEPA_N3 = 0\n",
    "ZSCOT_N0 = 0\n",
    "ZSCOT_N1 = 0\n",
    "ZSCOT_N2 = 0\n",
    "ZSCOT_N3 = 0\n",
    "GT_N0 = 0\n",
    "GT_N1 = 0\n",
    "GT_N2 = 0\n",
    "GT_N3 = 0\n",
    "\n",
    "run_lst = [0,1,3,4,5,6,7,9]\n",
    "for run in run_lst:\n",
    "    # print(f\"Run {run}, memory 40\")\n",
    "    n_test_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_n03_dynamic_test_{run}_outof_10runs.csv\").sort_values(by=\"patient_filename\")\n",
    "    n_zs_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zs_test_800.csv\").sort_values(by=\"patient_filename\")\n",
    "    n_zscot_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zscot_test_800.csv\").sort_values(by=\"patient_filename\")\n",
    "\n",
    "    split_ids = n_test_df.patient_filename\n",
    "    n_zs_df = n_zs_df[n_zs_df.patient_filename.isin(split_ids)]\n",
    "    n_zscot_df = n_zscot_df[n_zscot_df.patient_filename.isin(split_ids)]\n",
    "    for memory_patient, zs_patient, zscot_patient in zip(n_test_df.patient_filename, n_zs_df.patient_filename, n_zscot_df.patient_filename):\n",
    "        assert memory_patient == zs_patient and memory_patient == zscot_patient\n",
    "\n",
    "    ids_set = set()\n",
    "    label_dict = {\"N0\": set(), \"N1\": set(), \"N2\": set(), \"N3\": set()}\n",
    "    memory_pred_dict = {\"N0\": set(), \"N1\": set(), \"N2\": set(), \"N3\": set()}\n",
    "    memory_correct_dict = {\"N0\": set(), \"N1\": set(), \"N2\": set(), \"N3\": set()}\n",
    "    zs_pred_dict = {\"N0\": set(), \"N1\": set(), \"N2\": set(), \"N3\": set()}\n",
    "    zs_correct_dict = {\"N0\": set(), \"N1\": set(), \"N2\": set(), \"N3\": set()}\n",
    "    zscot_pred_dict = {\"N0\": set(), \"N1\": set(), \"N2\": set(), \"N3\": set()}\n",
    "    zscot_correct_dict = {\"N0\": set(), \"N1\": set(), \"N2\": set(), \"N3\": set()}\n",
    "    three_common_dict = {\"N0\": set(), \"N1\": set(), \"N2\": set(), \"N3\": set()}\n",
    "    both_same_pred_but_wrong_answer_dict = {\"N0\": set(), \"N1\": set(), \"N2\": set(), \"N3\": set()} # each key represents pred\n",
    "    neither_correct_dict = {\"N0\": set(), \"N1\": set(), \"N2\": set(), \"N3\": set()} # each key represents label\n",
    "    for idx, (filename, label, memory_ans, zs_ans, zscot_ans) in enumerate(zip(n_test_df.patient_filename, n_test_df.n, n_test_df[f\"cmem_n_40reports_ans_str\"], n_zs_df.zs_n_ans_str, n_zscot_df.zs_n_ans_str)):\n",
    "        memory_ans = memory_ans.upper().replace(\"NO\", \"N0\").replace(\"NL\", \"N1\")\n",
    "        zscot_ans = zscot_ans.upper().replace(\"NO\", \"N0\").replace(\"NL\", \"N1\")\n",
    "        if f\"N{label}\" == \"N0\":\n",
    "            label_dict[\"N0\"].add(filename)\n",
    "            if f\"N{label}\" in zscot_ans and f\"N{label}\" in memory_ans:\n",
    "                three_common_dict[\"N0\"].add(filename)\n",
    "            elif f\"N{label}\" not in zscot_ans and f\"N{label}\" not in memory_ans:\n",
    "                neither_correct_dict[\"N0\"].add(filename)\n",
    "        if f\"N{label}\" == \"N1\":\n",
    "            label_dict[\"N1\"].add(filename)\n",
    "            if f\"N{label}\" in zscot_ans and f\"N{label}\" in memory_ans:\n",
    "                three_common_dict[\"N1\"].add(filename)\n",
    "            elif f\"N{label}\" not in zscot_ans and f\"N{label}\" not in memory_ans:\n",
    "                neither_correct_dict[\"N1\"].add(filename)\n",
    "        if f\"N{label}\" == \"N2\":\n",
    "            label_dict[\"N2\"].add(filename)\n",
    "            if f\"N{label}\" in zscot_ans and f\"N{label}\" in memory_ans:\n",
    "                three_common_dict[\"N2\"].add(filename)\n",
    "            elif f\"N{label}\" not in zscot_ans and f\"N{label}\" not in memory_ans:\n",
    "                neither_correct_dict[\"N2\"].add(filename)\n",
    "        if f\"N{label}\" == \"N3\":\n",
    "            label_dict[\"N3\"].add(filename)\n",
    "            if f\"N{label}\" in zscot_ans and f\"N{label}\" in memory_ans:\n",
    "                three_common_dict[\"N3\"].add(filename)\n",
    "            elif f\"N{label}\" not in zscot_ans and f\"N{label}\" not in memory_ans:\n",
    "                neither_correct_dict[\"N3\"].add(filename)\n",
    "        # if (f\"N{label}\" in zs_ans) and (f\"N{label}\" in memory_ans): # cases where both are correct\n",
    "        # if (f\"N{label}\" not in zs_ans) and (f\"N{label}\" in memory_ans): # cases where only memory was correct\n",
    "        # if (f\"N{label}\" in zs_ans) and (f\"N{label}\" not in memory_ans): # cases where only zs was correct\n",
    "        # if (f\"N{label}\" not in zs_ans) and (f\"N{label}\" not in memory_ans): # cases where both were wrong\n",
    "        if \"N0\" in memory_ans:\n",
    "            memory_pred_dict[\"N0\"].add(filename)\n",
    "            if \"N0\" == f\"N{label}\":\n",
    "                memory_correct_dict[\"N0\"].add(filename)\n",
    "        if \"N1\" in memory_ans:\n",
    "            memory_pred_dict[\"N1\"].add(filename)\n",
    "            if \"N1\" == f\"N{label}\":\n",
    "                memory_correct_dict[\"N1\"].add(filename)\n",
    "        if \"N2\" in memory_ans:\n",
    "            memory_pred_dict[\"N2\"].add(filename)\n",
    "            if \"N2\" == f\"N{label}\":\n",
    "                memory_correct_dict[\"N2\"].add(filename)\n",
    "        if \"N3\" in memory_ans:\n",
    "            memory_pred_dict[\"N3\"].add(filename)\n",
    "            if \"N3\" == f\"N{label}\":\n",
    "                memory_correct_dict[\"N3\"].add(filename)\n",
    "        if \"N0\" in zs_ans:\n",
    "            zs_pred_dict[\"N0\"].add(filename)\n",
    "            if \"N0\" == f\"N{label}\":\n",
    "                zs_correct_dict[\"N0\"].add(filename)\n",
    "        if \"N1\" in zs_ans:\n",
    "            zs_pred_dict[\"N1\"].add(filename)\n",
    "            if \"N1\" == f\"N{label}\":\n",
    "                zs_correct_dict[\"N1\"].add(filename)\n",
    "        if \"N2\" in zs_ans:\n",
    "            zs_pred_dict[\"N2\"].add(filename)\n",
    "            if \"N2\" == f\"N{label}\":\n",
    "                zs_correct_dict[\"N2\"].add(filename)\n",
    "        if \"N3\" in zs_ans:\n",
    "            zs_pred_dict[\"N3\"].add(filename)\n",
    "            if \"N3\" == f\"N{label}\":\n",
    "                zs_correct_dict[\"N3\"].add(filename)\n",
    "        if \"N0\" in zscot_ans:\n",
    "            zscot_pred_dict[\"N0\"].add(filename)\n",
    "            if \"N0\" == f\"N{label}\":\n",
    "                zscot_correct_dict[\"N0\"].add(filename)\n",
    "        if \"N1\" in zscot_ans:\n",
    "            zscot_pred_dict[\"N1\"].add(filename)\n",
    "            if \"N1\" == f\"N{label}\":\n",
    "                zscot_correct_dict[\"N1\"].add(filename)\n",
    "        if \"N2\" in zscot_ans:\n",
    "            zscot_pred_dict[\"N2\"].add(filename)\n",
    "            if \"N2\" == f\"N{label}\":\n",
    "                zscot_correct_dict[\"N2\"].add(filename)\n",
    "        if \"N3\" in zscot_ans:\n",
    "            zscot_pred_dict[\"N3\"].add(filename)\n",
    "            if \"N3\" == f\"N{label}\":\n",
    "                zscot_correct_dict[\"N3\"].add(filename)\n",
    "        if \"N0\" in memory_ans and \"N0\" in zscot_ans and \"N0\" != f\"N{label}\":\n",
    "            both_same_pred_but_wrong_answer_dict[\"N0\"].add(filename)\n",
    "        if \"N1\" in memory_ans and \"N1\" in zscot_ans and \"N1\" != f\"N{label}\":\n",
    "            both_same_pred_but_wrong_answer_dict[\"N1\"].add(filename)\n",
    "        if \"N2\" in memory_ans and \"N2\" in zscot_ans and \"N2\" != f\"N{label}\":\n",
    "            both_same_pred_but_wrong_answer_dict[\"N2\"].add(filename)\n",
    "        if \"N3\" in memory_ans and \"N3\" in zscot_ans and \"N3\" != f\"N{label}\":\n",
    "            both_same_pred_but_wrong_answer_dict[\"N3\"].add(filename)\n",
    "            # ids_set.add(filename)\n",
    "\n",
    "    df1 = pd.DataFrame(\n",
    "        {\n",
    "            \"N0\": [f'{len(memory_pred_dict[\"N0\"])} pred ({len(memory_correct_dict[\"N0\"])} correct)', f'{len(zs_pred_dict[\"N0\"])} pred ({len(zs_correct_dict[\"N0\"])} correct)', f'{len(zscot_pred_dict[\"N0\"])} pred ({len(zscot_correct_dict[\"N0\"])} correct)', f'{len(label_dict[\"N0\"])}'],\n",
    "            \"N1\": [f'{len(memory_pred_dict[\"N1\"])} pred ({len(memory_correct_dict[\"N1\"])} correct)', f'{len(zs_pred_dict[\"N1\"])} pred ({len(zs_correct_dict[\"N1\"])} correct)', f'{len(zscot_pred_dict[\"N1\"])} pred ({len(zscot_correct_dict[\"N1\"])} correct)', f'{len(label_dict[\"N1\"])}'],\n",
    "            \"N2\": [f'{len(memory_pred_dict[\"N2\"])} pred ({len(memory_correct_dict[\"N2\"])} correct)', f'{len(zs_pred_dict[\"N2\"])} pred ({len(zs_correct_dict[\"N2\"])} correct)', f'{len(zscot_pred_dict[\"N2\"])} pred ({len(zscot_correct_dict[\"N2\"])} correct)', f'{len(label_dict[\"N2\"])}'],\n",
    "            \"N3\": [f'{len(memory_pred_dict[\"N3\"])} pred ({len(memory_correct_dict[\"N3\"])} correct)', f'{len(zs_pred_dict[\"N3\"])} pred ({len(zs_correct_dict[\"N3\"])} correct)', f'{len(zscot_pred_dict[\"N3\"])} pred ({len(zscot_correct_dict[\"N3\"])} correct)', f'{len(label_dict[\"N3\"])}']\n",
    "        },\n",
    "        index=[\"KEPA\", \"ZS\", \"ZSCOT\", \"Ground Truth\"]\n",
    "    )\n",
    "    # display(df1.transpose())\n",
    "    print(f\"{len(memory_pred_dict['N0'])}, {len(memory_pred_dict['N1'])}, {len(memory_pred_dict['N2'])}, {len(memory_pred_dict['N3'])}\", end=\"\\t\")\n",
    "    print(f\"{len(zs_pred_dict['N0'])}, {len(zs_pred_dict['N1'])}, {len(zs_pred_dict['N2'])}, {len(zs_pred_dict['N3'])}\", end=\"\\t\")\n",
    "    print(f\"{len(zscot_pred_dict['N0'])}, {len(zscot_pred_dict['N1'])}, {len(zscot_pred_dict['N2'])}, {len(zscot_pred_dict['N3'])}\", end=\"\\t\")\n",
    "    print(f\"{len(label_dict['N0'])}, {len(label_dict['N1'])}, {len(label_dict['N2'])}, {len(label_dict['N3'])}\")\n",
    "    KEPA_N0 += len(memory_pred_dict[\"N0\"])\n",
    "    KEPA_N1 += len(memory_pred_dict[\"N1\"])\n",
    "    KEPA_N2 += len(memory_pred_dict[\"N2\"])\n",
    "    KEPA_N3 += len(memory_pred_dict[\"N3\"])\n",
    "    ZSCOT_N0 += len(zscot_pred_dict[\"N0\"])\n",
    "    ZSCOT_N1 += len(zscot_pred_dict[\"N1\"])\n",
    "    ZSCOT_N2 += len(zscot_pred_dict[\"N2\"])\n",
    "    ZSCOT_N3 += len(zscot_pred_dict[\"N3\"])\n",
    "    GT_N0 += len(label_dict[\"N0\"])\n",
    "    GT_N1 += len(label_dict[\"N1\"])\n",
    "    GT_N2 += len(label_dict[\"N2\"])\n",
    "    GT_N3 += len(label_dict[\"N3\"])\n",
    "\n",
    "    memory_pv = np.array([len(memory_pred_dict[\"N0\"]), len(memory_pred_dict[\"N1\"]), len(memory_pred_dict[\"N2\"]), len(memory_pred_dict[\"N3\"])]) / (len(memory_pred_dict[\"N0\"]) + len(memory_pred_dict[\"N1\"]) + len(memory_pred_dict[\"N2\"]) + len(memory_pred_dict[\"N3\"]))\n",
    "    zs_pv = np.array([len(zs_pred_dict[\"N0\"]), len(zs_pred_dict[\"N1\"]), len(zs_pred_dict[\"N2\"]), len(zs_pred_dict[\"N3\"])]) / (len(zs_pred_dict[\"N0\"]) + len(zs_pred_dict[\"N1\"]) + len(zs_pred_dict[\"N2\"]) + len(zs_pred_dict[\"N3\"]))\n",
    "    zscot_pv = np.array([len(zscot_pred_dict[\"N0\"]), len(zscot_pred_dict[\"N1\"]), len(zscot_pred_dict[\"N2\"]), len(zscot_pred_dict[\"N3\"])]) / (len(zscot_pred_dict[\"N0\"]) + len(zscot_pred_dict[\"N1\"]) + len(zscot_pred_dict[\"N2\"]) + len(zscot_pred_dict[\"N3\"]))\n",
    "    gt_pv = np.array([len(label_dict[\"N0\"]), len(label_dict[\"N1\"]), len(label_dict[\"N2\"]), len(label_dict[\"N3\"])]) / (len(label_dict[\"N0\"]) + len(label_dict[\"N1\"]) + len(label_dict[\"N2\"]) + len(label_dict[\"N3\"]))\n",
    "    # print(memory_pv, zscot_pv, gt_pv)\n",
    "    # print(\"Jensen-Shannon distance between kepa and ground truth: \" ,jensenshannon(memory_pv, gt_pv))\n",
    "    # print(\"Jensen-Shannon distance between zs and ground truth: \" ,jensenshannon(zs_pv, gt_pv))\n",
    "    # print(\"Jensen-Shannon distance between zscot and ground truth: \" ,jensenshannon(zscot_pv, gt_pv))\n",
    "    df2 = pd.DataFrame(\n",
    "        {\n",
    "            \"N0\": [f'{len(three_common_dict[\"N0\"])}', f'{len(memory_pred_dict[\"N0\"])}', f'{len(zscot_pred_dict[\"N0\"])}', f'{len(both_same_pred_but_wrong_answer_dict[\"N0\"])}'],\n",
    "            \"N1\": [f'{len(three_common_dict[\"N1\"])}', f'{len(memory_pred_dict[\"N1\"])}', f'{len(zscot_pred_dict[\"N1\"])}', f'{len(both_same_pred_but_wrong_answer_dict[\"N1\"])}'],\n",
    "            \"N2\": [f'{len(three_common_dict[\"N2\"])}', f'{len(memory_pred_dict[\"N2\"])}', f'{len(zscot_pred_dict[\"N2\"])}', f'{len(both_same_pred_but_wrong_answer_dict[\"N2\"])}'],\n",
    "            \"N3\": [f'{len(three_common_dict[\"N3\"])}', f'{len(memory_pred_dict[\"N3\"])}', f'{len(zscot_pred_dict[\"N3\"])}', f'{len(both_same_pred_but_wrong_answer_dict[\"N3\"])}']\n",
    "        },  \n",
    "        index=[\"3 common\", \"KEPA\", \"ZSCOT\", \"Both same pred but wrong answer\"]         \n",
    "    )\n",
    "    # display(df2.transpose())\n",
    "    # print()\n",
    "\n",
    "# print(\"Total\")\n",
    "df3 = pd.DataFrame(\n",
    "    {\n",
    "        \"N0\": [f'{KEPA_N0/len(run_lst)}', f'{ZSCOT_N0/len(run_lst)}', f'{GT_N0/len(run_lst)}'],\n",
    "        \"N1\": [f'{KEPA_N1/len(run_lst)}', f'{ZSCOT_N1/len(run_lst)}', f'{GT_N1/len(run_lst)}'],\n",
    "        \"N2\": [f'{KEPA_N2/len(run_lst)}', f'{ZSCOT_N2/len(run_lst)}', f'{GT_N2/len(run_lst)}'],\n",
    "        \"N3\": [f'{KEPA_N3/len(run_lst)}', f'{ZSCOT_N3/len(run_lst)}', f'{GT_N3/len(run_lst)}']\n",
    "    },\n",
    "    index=[\"KEPA\", \"ZSCOT\", \"Ground Truth\"]\n",
    ")\n",
    "# display(df3.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(memory_pred_dict['N3'] - three_common_dict[\"N3\"] - both_same_pred_but_wrong_answer_dict[\"N3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(neither_correct_dict['N3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ids_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve reports that satisfy a specific condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_consistency(ans, lst):\n",
    "    if len(lst) != 10:\n",
    "        print(lst)\n",
    "        raise ValueError(\"Exactly 10 arguments are required.\")\n",
    "\n",
    "    lst = [arg.upper().replace(\"NO\", \"N0\").replace(\"NL\", \"N1\") for arg in lst]\n",
    "    if f\"N{ans}\" not in lst:\n",
    "        return False\n",
    "    \n",
    "    count_dict = {}\n",
    "    for arg in lst:\n",
    "        if \"N0\" in arg:\n",
    "            arg = \"N0\"\n",
    "        elif \"N1\" in arg:\n",
    "            arg = \"N1\"\n",
    "        elif \"N2\" in arg:\n",
    "            arg = \"N2\"\n",
    "        elif \"N3\" in arg:\n",
    "            arg = \"N3\"\n",
    "            \n",
    "        if arg in count_dict:\n",
    "            count_dict[arg] += 1\n",
    "        else:\n",
    "            count_dict[arg] = 1\n",
    "\n",
    "        if count_dict[arg] >= 7:\n",
    "            return False\n",
    "\n",
    "    print(count_dict)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun():\n",
    "    file_name = \"TCGA-AO-A0J9.1E3F3136-6D86-4470-85AA-55B11C9E24CD\"\n",
    "    mem_reasoning = \"\"\n",
    "    txt =\"\"\"...\"\"\" \n",
    "    weird_lst = {}\n",
    "    for n in range(10):\n",
    "        test_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_n03_dynamic_test_{n}_outof_10runs.csv\")\n",
    "        train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/n03_memory_dataset{n}.csv\")\n",
    "        weird_lst[f\"{n}_split\"] = {}\n",
    "        for i in range(len(test_df)):\n",
    "            if file_name == test_df.iloc[i].patient_filename:\n",
    "            # if txt.strip() == report.strip():\n",
    "                # print(file_name)\n",
    "                # print(zs_predict_prompt_n03.format(report=test_df.iloc[i].text))\n",
    "                print(test_df.iloc[i].text)\n",
    "                return\n",
    "                # print(report)\n",
    "                # print(idx)\n",
    "            # if check_consistency(test_df.loc[i].n, test_df.loc[i][[\"cmem_n_10reports_ans_str\", \"cmem_n_20reports_ans_str\", \"cmem_n_30reports_ans_str\", \"cmem_n_40reports_ans_str\", \"cmem_n_50reports_ans_str\", \"cmem_n_60reports_ans_str\", \"cmem_n_70reports_ans_str\", \"cmem_n_80reports_ans_str\", \"cmem_n_90reports_ans_str\", \"cmem_n_100reports_ans_str\"]].tolist()):\n",
    "            #     print(test_df.loc[i].patient_filename)\n",
    "            #     print(test_df.loc[i].n)\n",
    "            #     weird_lst[f\"{n}_split\"][test_df.loc[i].patient_filename] = {\"answer\": f\"N{test_df.loc[i].n}\", \"report\": test_df.loc[i].text, \"kepa(mem_reas_pred)\": [(mem, reas, pred) for mem, reas, pred in zip(train_df.cmem_n_memory_str.tolist()[9::10],test_df.loc[i][[\"cmem_n_10reasoning\", \"cmem_n_20reasoning\", \"cmem_n_30reasoning\", \"cmem_n_40reasoning\", \"cmem_n_50reasoning\", \"cmem_n_60reasoning\", \"cmem_n_70reasoning\", \"cmem_n_80reasoning\", \"cmem_n_90reasoning\", \"cmem_n_100reasoning\"]].tolist(), test_df.loc[i][[\"cmem_n_10reports_ans_str\", \"cmem_n_20reports_ans_str\", \"cmem_n_30reports_ans_str\", \"cmem_n_40reports_ans_str\", \"cmem_n_50reports_ans_str\", \"cmem_n_60reports_ans_str\", \"cmem_n_70reports_ans_str\", \"cmem_n_80reports_ans_str\", \"cmem_n_90reports_ans_str\", \"cmem_n_100reports_ans_str\"]].tolist())]}\n",
    "                \n",
    "fun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weird_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_dict = {}\n",
    "# id_lst = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/weird_n03.csv\")['Unnamed: 0'].tolist()\n",
    "# answer_lst = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/weird_n03.csv\")['answer'].tolist()\n",
    "# report_lst = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/weird_n03.csv\")['report'].tolist()\n",
    "\n",
    "# for patient, answer, report in zip(id_lst, answer_lst, report_lst):\n",
    "#     error_dict[patient] = {}\n",
    "#     error_dict[patient][\"answer\"] = f\"N{answer}\"\n",
    "#     error_dict[patient][\"report\"] = report\n",
    "#     error_dict[patient][\"kepa\"] = {\"N0\": [], \"N1\": [], \"N2\": [], \"N3\": []}\n",
    "\n",
    "# for patient in id_lst:\n",
    "#     for i in range(10):\n",
    "#         obj = weird_lst[f'{i}split'].get(patient)\n",
    "#         if obj is not None:\n",
    "#             error_dict[patient][\"answer\"] = obj[\"answer\"]\n",
    "#             error_dict[patient][\"report\"] = obj[\"report\"]\n",
    "#             for n in range(10):\n",
    "#                 pred = obj[\"kepa(mem_reas_pred)\"][n][2].upper().replace(\"NO\", \"N0\").replace(\"NL\", \"N1\")\n",
    "#                 if \"N0\" in pred:\n",
    "#                     error_dict[patient][\"kepa\"][\"N0\"].append({\"memory\": obj[\"kepa(mem_reas_pred)\"][n][0], \"reasoning\": obj[\"kepa(mem_reas_pred)\"][n][1]})\n",
    "#                 elif \"N1\" in pred:\n",
    "#                     error_dict[patient][\"kepa\"][\"N1\"].append({\"memory\": obj[\"kepa(mem_reas_pred)\"][n][0], \"reasoning\": obj[\"kepa(mem_reas_pred)\"][n][1]})\n",
    "#                 elif \"N2\" in pred:\n",
    "#                     error_dict[patient][\"kepa\"][\"N2\"].append({\"memory\": obj[\"kepa(mem_reas_pred)\"][n][0], \"reasoning\": obj[\"kepa(mem_reas_pred)\"][n][1]})\n",
    "#                 elif \"N3\" in pred:\n",
    "#                     error_dict[patient][\"kepa\"][\"N3\"].append({\"memory\": obj[\"kepa(mem_reas_pred)\"][n][0], \"reasoning\": obj[\"kepa(mem_reas_pred)\"][n][1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('weird_n03.json', 'w') as json_file:\n",
    "#     json.dump(error_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zs cot\n",
    "t_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zscot_test_800.csv\")\n",
    "print(t14_calculate_metrics(t_df['t'], t_df['zs_t_ans_str']))\n",
    "\n",
    "n_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zscot_test_800.csv\")\n",
    "print(n03_calculate_metrics(n_df['n'], n_df['zs_n_ans_str']))\n",
    "\n",
    "# zs\n",
    "t_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zs_test_800.csv\")\n",
    "print(t14_calculate_metrics(t_df['t'], t_df['zs_t_ans_str']))\n",
    "\n",
    "n_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zs_test_800.csv\")\n",
    "print(n03_calculate_metrics(n_df['n'], n_df['zs_n_ans_str']))\n",
    "\n",
    "# ensReas\n",
    "t_df = pd.read_csv(\"/secure/shared_data/rag_tnm_results/t14_results/mixtral_ensReas_step1/brca_t14_merged_df_800.csv\")\n",
    "print(t14_calculate_metrics(t_df['t'], t_df['sc_ans']))\n",
    "\n",
    "n_df = pd.read_csv(\"/secure/shared_data/rag_tnm_results/n03_results/mixtral_ensReas_step1/brca_n03_merged_df.csv\")\n",
    "print(n03_calculate_metrics(n_df['n'], n_df['sc_ans']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(results, cat):\n",
    "    precision_list = [result[cat]['precision'] for result in results]\n",
    "    recall_list = [result[cat]['recall'] for result in results]\n",
    "    f1_list = [result[cat]['f1'] for result in results]\n",
    "    support_list = [result[cat]['support'] for result in results]\n",
    "    num_errors_list = [result[cat]['num_errors'] for result in results]\n",
    "    \n",
    "    mean_precision = sum(precision_list) / len(precision_list)\n",
    "    mean_recall = sum(recall_list) / len(recall_list)\n",
    "    mean_f1 = sum(f1_list) / len(f1_list)\n",
    "    \n",
    "    std_precision = (sum([(x - mean_precision)**2 for x in precision_list]) / len(precision_list))**0.5\n",
    "    std_recall = (sum([(x - mean_recall)**2 for x in recall_list]) / len(recall_list))**0.5\n",
    "    std_f1 = (sum([(x - mean_f1)**2 for x in f1_list]) / len(f1_list))**0.5\n",
    "    \n",
    "    return {\n",
    "        'mean_precision': round(mean_precision, 3),\n",
    "        'mean_recall': round(mean_recall, 3),\n",
    "        'mean_f1': round(mean_f1, 3),\n",
    "        'std_precision': round(std_precision, 3),\n",
    "        'std_recall': round(std_recall, 3),\n",
    "        'std_f1': round(std_f1, 3),\n",
    "        'sum_support': sum(support_list),\n",
    "        'sum_num_errors': sum(num_errors_list),\n",
    "        'raw_mean_precision': mean_precision,\n",
    "        'raw_mean_recall': mean_recall,\n",
    "        'raw_mean_f1': mean_f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(results, cat):\n",
    "    precision_list = [result[cat]['precision'] for result in results]\n",
    "    recall_list = [result[cat]['recall'] for result in results]\n",
    "    f1_list = [result[cat]['f1'] for result in results]\n",
    "    support_list = [result[cat]['support'] for result in results]\n",
    "    num_errors_list = [result[cat]['num_errors'] for result in results]\n",
    "    \n",
    "    mean_precision = sum(precision_list) / len(precision_list)\n",
    "    mean_recall = sum(recall_list) / len(recall_list)\n",
    "    mean_f1 = sum(f1_list) / len(f1_list)\n",
    "    \n",
    "    std_precision = (sum([(x - mean_precision)**2 for x in precision_list]) / len(precision_list))**0.5\n",
    "    std_recall = (sum([(x - mean_recall)**2 for x in recall_list]) / len(recall_list))**0.5\n",
    "    std_f1 = (sum([(x - mean_f1)**2 for x in f1_list]) / len(f1_list))**0.5\n",
    "    \n",
    "    return {\n",
    "        'mean_precision': round(mean_precision, 3),\n",
    "        'mean_recall': round(mean_recall, 3),\n",
    "        'mean_f1': round(mean_f1, 3),\n",
    "        'std_precision': round(std_precision, 3),\n",
    "        'std_recall': round(std_recall, 3),\n",
    "        'std_f1': round(std_f1, 3),\n",
    "        'sum_support': sum(support_list),\n",
    "        'sum_num_errors': sum(num_errors_list),\n",
    "        'raw_mean_precision': mean_precision,\n",
    "        'raw_mean_recall': mean_recall,\n",
    "        'raw_mean_f1': mean_f1,\n",
    "    }\n",
    "\n",
    "def output_tabular_performance(results, categories = ['T1', 'T2', 'T3', 'T4']):\n",
    "    precisions =[]\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "\n",
    "    for category in categories:\n",
    "        eval = calculate_mean_std(results, category)\n",
    "        print(\"{} {:.3f}({:.3f}) {:.3f}({:.3f}) {:.3f}({:.3f})\".format(category, eval[\"mean_precision\"], eval[\"std_precision\"], eval[\"mean_recall\"], eval[\"std_recall\"], eval[\"mean_f1\"], eval[\"std_f1\"]))\n",
    "        \n",
    "        # for calculating macro average\n",
    "        precisions.append(eval['raw_mean_precision'])\n",
    "        recalls.append(eval['raw_mean_recall'])\n",
    "        f1s.append(eval['raw_mean_f1'])\n",
    "\n",
    "    print(\"MacroAvg. {:.3f} {:.3f} {:.3f}\".format(round(sum(precisions)/len(precisions), 3), round(sum(recalls)/len(recalls), 3), round(sum(f1s)/len(f1s), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t14\n",
    "zs_t = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zs_test_800.csv\")\n",
    "zscot_t = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zscot_test_800.csv\")\n",
    "ensReas_t = pd.read_csv(\"/secure/shared_data/rag_tnm_results/t14_results/mixtral_ensReas_step1/brca_t14_merged_df_800.csv\")\n",
    "\n",
    "zs_t_results = []\n",
    "zscot_t_results = []\n",
    "ensReas_t_results = []\n",
    "kepa_t_results = []\n",
    "\n",
    "for run in range(1):\n",
    "    print(run)\n",
    "    split_ids = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/t14_test_{run}.csv\").patient_filename\n",
    "    zs_t_split = zs_t[zs_t.patient_filename.isin(split_ids)]\n",
    "    zs_t_results.append(t14_calculate_metrics(zs_t_split['t'], zs_t_split['zs_t_ans_str']))\n",
    "\n",
    "    zscot_t_split = zscot_t[zscot_t.patient_filename.isin(split_ids)]\n",
    "    zscot_t_results.append(t14_calculate_metrics(zscot_t_split['t'], zscot_t_split['zs_t_ans_str']))\n",
    "\n",
    "    ensReas_t_split = ensReas_t[ensReas_t.patient_filename.isin(split_ids)]\n",
    "    ensReas_t_results.append(t14_calculate_metrics(ensReas_t_split['t'], ensReas_t_split['sc_ans']))\n",
    "\n",
    "    df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_t14_dynamic_test_{run}_outof_10runs.csv\")\n",
    "    kepa_t_results.append(t14_calculate_metrics(df['t'], df['cmem_t_40reports_ans_str']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscot\n",
    "output_tabular_performance(zscot_t_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kepa\n",
    "output_tabular_performance(kepa_t_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = zscot_t_results\n",
    "\n",
    "categories = ['T1', 'T2', 'T3', 'T4']\n",
    "metrics = {category: calculate_mean_std(results, category) for category in categories}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions =[]\n",
    "recalls = []\n",
    "f1s = []\n",
    "for key, value in metrics.items():\n",
    "    precisions.append(value['raw_mean_precision'])\n",
    "    recalls.append(value['raw_mean_recall'])\n",
    "    f1s.append(value['raw_mean_f1'])\n",
    "    \n",
    "# print(round(sum(precisions)/len(precisions), 3), round(sum(recalls)/len(recalls), 3), round(sum(f1s)/len(f1s), 3))\n",
    "# print in dictionary\n",
    "print({'macro_average_precision': round(sum(precisions)/len(precisions), 3), 'macro_average_recall': round(sum(recalls)/len(recalls), 3), 'macro_average_f1': round(sum(f1s)/len(f1s), 3)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n03\n",
    "zs_n = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zs_test_800.csv\")\n",
    "zscot_n = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zscot_test_800.csv\")\n",
    "ensReas_n = pd.read_csv(\"/secure/shared_data/rag_tnm_results/n03_results/mixtral_ensReas_step1/brca_n03_merged_df.csv\")\n",
    "\n",
    "zs_n_results = []\n",
    "zscot_n_results = []\n",
    "ensReas_n_results = []\n",
    "kepa_n_results = []\n",
    "\n",
    "for run in range(1, 2):\n",
    "    print(run)\n",
    "    split_ids = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/n03_test_{run}.csv\").patient_filename\n",
    "    zs_n_split = zs_n[zs_n.patient_filename.isin(split_ids)]\n",
    "    zs_n_results.append(n03_calculate_metrics(zs_n_split['n'], zs_n_split['zs_n_ans_str']))\n",
    "\n",
    "    zscot_n_split = zscot_n[zscot_n.patient_filename.isin(split_ids)]\n",
    "    zscot_n_results.append(n03_calculate_metrics(zscot_n_split['n'], zscot_n_split['zs_n_ans_str']))\n",
    "\n",
    "    ensReas_n_split = ensReas_n[ensReas_n.patient_filename.isin(split_ids)]\n",
    "    ensReas_n_results.append(n03_calculate_metrics(ensReas_n_split['n'], ensReas_n_split['sc_ans']))\n",
    "\n",
    "    df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_n03_dynamic_test_{run}_outof_10runs.csv\")\n",
    "    kepa_n_results.append(n03_calculate_metrics(df['n'], df['cmem_n_40reports_ans_str']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscot\n",
    "output_tabular_performance(zscot_n_results, ['N0', 'N1', 'N2', 'N3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kepa\n",
    "output_tabular_performance(kepa_n_results, ['N0', 'N1', 'N2', 'N3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = kepa_n_results\n",
    "categories = ['N0', 'N1', 'N2', 'N3']\n",
    "metrics = {category: calculate_mean_std(results, category) for category in categories}\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precisions =[]\n",
    "recalls = []\n",
    "f1s = []\n",
    "for key, value in metrics.items():\n",
    "    precisions.append(value['raw_mean_precision'])\n",
    "    recalls.append(value['raw_mean_recall'])\n",
    "    f1s.append(value['raw_mean_f1'])\n",
    "\n",
    "# round(sum(precisions)/len(precisions), 3), round(sum(recalls)/len(recalls), 3), round(sum(f1s)/len(f1s), 3)\n",
    "# print in dictionary\n",
    "print({'macro_average_precision': round(sum(precisions)/len(precisions), 3), 'macro_average_recall': round(sum(recalls)/len(recalls), 3), 'macro_average_f1': round(sum(f1s)/len(f1s), 3)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot scores for 10 splits, given 10 memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual graph\n",
    "\n",
    "zs_t = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zs_test_800.csv\")\n",
    "zscot_t = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zscot_test_800.csv\")\n",
    "df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0914_rag_test.csv\")\n",
    "\n",
    "for run in range(10):\n",
    "    # t14 training data to extract memory\n",
    "    t_train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/t14_memory_dataset{run}.csv\")\n",
    "    memory_tup = []\n",
    "    for idx, row in t_train_df.iterrows():\n",
    "        # if row[\"cmem_t_is_updated\"] == True:\n",
    "        memory_tup.append((idx+1,row['cmem_t_memory_str']))\n",
    "    memory_tup = memory_tup[9::10]\n",
    "    df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_t14_dynamic_test_{run}_outof_10runs.csv\")\n",
    "    split_ids = df.patient_filename\n",
    "    zs_t_split = zs_t[zs_t.patient_filename.isin(split_ids)]\n",
    "    zscot_t_split = zscot_t[zscot_t.patient_filename.isin(split_ids)]\n",
    "    df_split = df[df.patient_filename.isin(split_ids)]\n",
    "\n",
    "    for i, _ in memory_tup:\n",
    "        if len(df[df[f\"cmem_t_{i}reports_is_parsed\"]==False]) > 0:\n",
    "            print(f\"parsing error at memory {i}\")\n",
    "\n",
    "\n",
    "   # gather y-axis data\n",
    "    precision_lst = []\n",
    "    recall_lst = []\n",
    "    f1_lst = []\n",
    "\n",
    "    zs_precision = t14_calculate_metrics(zs_t_split['t'], zs_t_split['zs_t_ans_str'])['overall']['macro_precision']\n",
    "    zs_recall = t14_calculate_metrics(zs_t_split['t'], zs_t_split['zs_t_ans_str'])['overall']['macro_recall']\n",
    "    zs_f1 = t14_calculate_metrics(zs_t_split['t'], zs_t_split['zs_t_ans_str'])['overall']['macro_f1']\n",
    "\n",
    "    zscot_precision = t14_calculate_metrics(zscot_t_split['t'], zscot_t_split['zs_t_ans_str'])['overall']['macro_precision']\n",
    "    zscot_recall = t14_calculate_metrics(zscot_t_split['t'], zscot_t_split['zs_t_ans_str'])['overall']['macro_recall']\n",
    "    zscot_f1 = t14_calculate_metrics(zscot_t_split['t'], zscot_t_split['zs_t_ans_str'])['overall']['macro_f1']\n",
    "\n",
    "    rag_precision = t14_calculate_metrics(df_split['t'], df_split['cmem_t_ans_str'])['overall']['macro_precision']\n",
    "    rag_recall = t14_calculate_metrics(df_split['t'], df_split['cmem_t_ans_str'])['overall']['macro_recall']\n",
    "    rag_f1 = t14_calculate_metrics(df_split['t'], df_split['cmem_t_ans_str'])['overall']['macro_f1']\n",
    "\n",
    "    x_idx = []\n",
    "    for i, _ in memory_tup:\n",
    "        x_idx.append(i)\n",
    "        result = t14_calculate_metrics(df['t'], df[f'cmem_t_{i}reports_ans_str'])['overall']\n",
    "        precision_lst.append(result['macro_precision'])\n",
    "        recall_lst.append(result['macro_recall'])\n",
    "        f1_lst.append(result['macro_f1'])\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    plt.plot(x_idx, precision_lst, label='Memory Precision', color='blue', marker='o')\n",
    "    plt.plot(x_idx, recall_lst, label='Memory Recall', color='green', marker='o')\n",
    "    plt.plot(x_idx, f1_lst, label='Memory F1 Score', color='red', marker='o')\n",
    "\n",
    "    # plt.axhline(y=zs_precision, color='blue', linestyle='--', label='ZS Precision')\n",
    "    # plt.axhline(y=zs_recall, color='green', linestyle='--', label='ZS Recall')\n",
    "    # plt.axhline(y=zs_f1, color='red', linestyle='--', label='ZS F1 Score')\n",
    "    plt.axhline(y=rag_precision, color='blue', linestyle='--', label='RAG Precision')\n",
    "    plt.axhline(y=rag_recall, color='green', linestyle='--', label='RAG Recall')\n",
    "    plt.axhline(y=rag_f1, color='red', linestyle='--', label='RAG F1 Score')\n",
    "\n",
    "    plt.axhline(y=zscot_precision, color='blue', linestyle='-.', label='ZSCOT Precision')\n",
    "    plt.axhline(y=zscot_recall, color='green', linestyle='-.', label='ZSCOT Recall')\n",
    "    plt.axhline(y=zscot_f1, color='red', linestyle='-.', label='ZSCOT F1 Score')\n",
    "    \n",
    "    plt.xlabel(f'# of Reports for Memory (t14_train_{run}.csv)')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title(f'Testing Results on 700 test Reports (t14_test_{run}.csv)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average (with new metric)\n",
    "\n",
    "zs_t = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zs_test_800.csv\")\n",
    "zscot_t = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_t14_zscot_test_800.csv\")\n",
    "df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0914_rag_test.csv\")\n",
    "\n",
    "\n",
    "zs_t_results = []\n",
    "zscot_t_results = []\n",
    "rag_t_results = []\n",
    "\n",
    "total_run = 10\n",
    "for run in range(total_run):\n",
    "    split_ids = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/t14_test_{run}.csv\").patient_filename\n",
    "    zs_t_split = zs_t[zs_t.patient_filename.isin(split_ids)]\n",
    "    zs_t_results.append(t14_calculate_metrics(zs_t_split['t'], zs_t_split['zs_t_ans_str'])['overall'])\n",
    "\n",
    "    zscot_t_split = zscot_t[zscot_t.patient_filename.isin(split_ids)]\n",
    "    zscot_t_results.append(t14_calculate_metrics(zscot_t_split['t'], zscot_t_split['zs_t_ans_str'])['overall'])\n",
    "    \n",
    "    df_split = df[df.patient_filename.isin(split_ids)]\n",
    "    rag_t_results.append(t14_calculate_metrics(df_split['t'], df_split['cmem_t_ans_str'])['overall'])\n",
    "\n",
    "zs_precision_avg = sum([rs['macro_precision'] for rs in zs_t_results])/len(zs_t_results)\n",
    "zs_recall_avg = sum([rs['macro_recall'] for rs in zs_t_results])/len(zs_t_results)\n",
    "zs_f1_avg = sum([rs['macro_f1'] for rs in zs_t_results])/len(zs_t_results)\n",
    "\n",
    "zscot_precision_avg = sum([rs['macro_precision'] for rs in zscot_t_results])/len(zscot_t_results)\n",
    "zscot_recall_avg = sum([rs['macro_recall'] for rs in zscot_t_results])/len(zscot_t_results)\n",
    "zscot_f1_avg = sum([rs['macro_f1'] for rs in zscot_t_results])/len(zscot_t_results)\n",
    "\n",
    "rag_precision_avg = sum([rs['macro_precision'] for rs in rag_t_results])/len(rag_t_results)\n",
    "rag_recall_avg = sum([rs['macro_recall'] for rs in rag_t_results])/len(rag_t_results)\n",
    "rag_f1_avg = sum([rs['macro_f1'] for rs in rag_t_results])/len(rag_t_results)\n",
    "\n",
    "x_axis = np.array(range(1, 11)) * 10\n",
    "\n",
    "memory_precision_cumulative = []\n",
    "memory_recall_cumulative = []\n",
    "memory_f1_cumulative = []\n",
    "\n",
    "\n",
    "for run in range(total_run):\n",
    "    df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_t14_dynamic_test_{run}_outof_10runs.csv\")\n",
    "\n",
    "    for i in np.array(range(1, 11)): # memory (10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n",
    "        result = t14_calculate_metrics(df['t'], df[f'cmem_t_{i*10}reports_ans_str'])['overall']\n",
    "        if run == 0:\n",
    "            memory_precision_cumulative.append(result['macro_precision'])\n",
    "            memory_recall_cumulative.append(result['macro_recall'])\n",
    "            memory_f1_cumulative.append(result['macro_f1'])\n",
    "        else:\n",
    "            memory_precision_cumulative[i-1] += result['macro_precision']\n",
    "            memory_recall_cumulative[i-1] += result['macro_recall']\n",
    "            memory_f1_cumulative[i-1] += result['macro_f1']\n",
    "\n",
    "\n",
    "# average\n",
    "precision_avg = [p / total_run for p in memory_precision_cumulative]\n",
    "recall_avg = [r / total_run for r in memory_recall_cumulative]\n",
    "f1_avg = [f / total_run for f in memory_f1_cumulative]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.plot(x_axis, precision_avg, label='Average KEPA Precision', color='blue', marker='o')\n",
    "plt.plot(x_axis, recall_avg, label='Average KEPA Recall', color='green', marker='o')\n",
    "plt.plot(x_axis, f1_avg, label='Average KEPA F1 Score', color='red', marker='o')\n",
    "\n",
    "\n",
    "plt.axhline(y=zscot_precision_avg, color='blue', linestyle=':', label='ZSCOT Precision')\n",
    "plt.axhline(y=zscot_recall_avg, color='green', linestyle=':', label='ZSCOT Recall')\n",
    "plt.axhline(y=zscot_f1_avg, color='red', linestyle=':', label='ZSCOT F1 Score')\n",
    "\n",
    "plt.axhline(y=rag_precision_avg, color='blue', linestyle='--', label='RAG Precision')\n",
    "plt.axhline(y=rag_recall_avg, color='green', linestyle='--', label='RAG Recall')\n",
    "plt.axhline(y=rag_f1_avg, color='red', linestyle='--', label='RAG F1 Score')\n",
    "\n",
    "plt.text(x_axis[-1] + 2, zscot_precision_avg, f'{zscot_precision_avg:.3f}', fontsize=9, ha='left', va='center', color='blue')\n",
    "plt.text(x_axis[-1] + 2, zscot_recall_avg, f'{zscot_recall_avg:.3f}', fontsize=9, ha='left', va='center', color='green')\n",
    "plt.text(x_axis[-1] + 2, zscot_f1_avg, f'{zscot_f1_avg:.3f}', fontsize=9, ha='left', va='center', color='red')\n",
    "\n",
    "\n",
    "plt.xlabel('Number of Training Reports')\n",
    "plt.ylabel('Scores')\n",
    "# plt.title(f'The Average of 10 Results on 700 Test Reports (t14)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual graph\n",
    "\n",
    "zs_n = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zs_test_800.csv\")\n",
    "zscot_n = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zscot_test_800.csv\")\n",
    "df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0914_rag_test.csv\")\n",
    "\n",
    "for run in range(10):\n",
    "    # n03 training data to extract memory\n",
    "    t_train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/n03_memory_dataset{run}.csv\")\n",
    "\n",
    "    memory_tup = []\n",
    "    for idx, row in t_train_df.iterrows():\n",
    "        # if row[\"cmem_t_is_updated\"] == True:\n",
    "        memory_tup.append((idx+1,row['cmem_n_memory_str']))\n",
    "    memory_tup = memory_tup[9::10]\n",
    "    df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_n03_dynamic_test_{run}_outof_10runs.csv\")\n",
    "    split_ids = df.patient_filename\n",
    "    zs_n_split = zs_n[zs_n.patient_filename.isin(split_ids)]\n",
    "    zscot_n_split = zscot_n[zscot_n.patient_filename.isin(split_ids)]\n",
    "    df_split = df[df.patient_filename.isin(split_ids)]\n",
    "\n",
    "\n",
    "    for i, _ in memory_tup:\n",
    "        if len(df[df[f\"cmem_n_{i}reports_is_parsed\"]==False]) > 0:\n",
    "            print(f\"parsing error at memory {i}\")\n",
    "\n",
    "\n",
    "   # gather y-axis data\n",
    "    precision_lst = []\n",
    "    recall_lst = []\n",
    "    f1_lst = []\n",
    "\n",
    "    zs_precision = n03_calculate_metrics(zs_n_split['n'], zs_n_split['zs_n_ans_str'])['overall']['macro_precision']\n",
    "    zs_recall = n03_calculate_metrics(zs_n_split['n'], zs_n_split['zs_n_ans_str'])['overall']['macro_recall']\n",
    "    zs_f1 = n03_calculate_metrics(zs_n_split['n'], zs_n_split['zs_n_ans_str'])['overall']['macro_f1']\n",
    "\n",
    "    zscot_precision = n03_calculate_metrics(zscot_n_split['n'], zscot_n_split['zs_n_ans_str'])['overall']['macro_precision']\n",
    "    zscot_recall = n03_calculate_metrics(zscot_n_split['n'], zscot_n_split['zs_n_ans_str'])['overall']['macro_recall']\n",
    "    zscot_f1 = n03_calculate_metrics(zscot_n_split['n'], zscot_n_split['zs_n_ans_str'])['overall']['macro_f1']\n",
    "\n",
    "    rag_precision = n03_calculate_metrics(df_split['n'], df_split['cmem_n_ans_str'])['overall']['macro_precision']\n",
    "    rag_recall = n03_calculate_metrics(df_split['n'], df_split['cmem_n_ans_str'])['overall']['macro_recall']\n",
    "    rag_f1 = n03_calculate_metrics(df_split['n'], df_split['cmem_n_ans_str'])['overall']['macro_f1']\n",
    "\n",
    "    x_idx = []\n",
    "    for i, _ in memory_tup:\n",
    "        x_idx.append(i)\n",
    "        result = n03_calculate_metrics(df['n'], df[f'cmem_n_{i}reports_ans_str'])['overall']\n",
    "        precision_lst.append(result['macro_precision'])\n",
    "        recall_lst.append(result['macro_recall'])\n",
    "        f1_lst.append(result['macro_f1'])\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    plt.plot(x_idx, precision_lst, label='Memory Precision', color='blue', marker='o')\n",
    "    plt.plot(x_idx, recall_lst, label='Memory Recall', color='green', marker='o')\n",
    "    plt.plot(x_idx, f1_lst, label='Memory F1 Score', color='red', marker='o')\n",
    "    \n",
    "    # plt.axhline(y=zs_precision, color='blue', linestyle='--', label='ZS Precision')\n",
    "    # plt.axhline(y=zs_recall, color='green', linestyle='--', label='ZS Recall')\n",
    "    # plt.axhline(y=zs_f1, color='red', linestyle='--', label='ZS F1 Score')\n",
    "\n",
    "    plt.axhline(y=rag_precision, color='blue', linestyle='--', label='RAG Precision')\n",
    "    plt.axhline(y=rag_recall, color='green', linestyle='--', label='RAG Recall')\n",
    "    plt.axhline(y=rag_f1, color='red', linestyle='--', label='RAG F1 Score')\n",
    "\n",
    "    plt.axhline(y=zscot_precision, color='blue', linestyle='-.', label='ZSCOT Precision')\n",
    "    plt.axhline(y=zscot_recall, color='green', linestyle='-.', label='ZSCOT Recall')\n",
    "    plt.axhline(y=zscot_f1, color='red', linestyle='-.', label='ZSCOT F1 Score')\n",
    "    \n",
    "    plt.xlabel(f'# of Reports for Memory (n03_train_{run}.csv)')\n",
    "    plt.ylabel('Scores')\n",
    "    plt.title(f'Testing Results on 700 test Reports (n03_test_{run}.csv)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average (with new metric)\n",
    "\n",
    "zs_n = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zs_test_800.csv\")\n",
    "zscot_n = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0716_n03_zscot_test_800.csv\")\n",
    "df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/result/0914_rag_test.csv\")\n",
    "\n",
    "zs_n_results = []\n",
    "zscot_n_results = []\n",
    "rag_n_results = []\n",
    "\n",
    "total_run = 10\n",
    "for run in range(total_run):\n",
    "    # if run == 8:\n",
    "    #     continue\n",
    "    split_ids = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/n03_test_{run}.csv\").patient_filename\n",
    "    zs_n_split = zs_n[zs_n.patient_filename.isin(split_ids)]\n",
    "    zs_n_results.append(n03_calculate_metrics(zs_n_split['n'], zs_n_split['zs_n_ans_str'])['overall'])\n",
    "\n",
    "    zscot_n_split = zscot_n[zscot_n.patient_filename.isin(split_ids)]\n",
    "    zscot_n_results.append(n03_calculate_metrics(zscot_n_split['n'], zscot_n_split['zs_n_ans_str'])['overall'])\n",
    "\n",
    "    df_split = df[df.patient_filename.isin(split_ids)]\n",
    "    rag_n_results.append(n03_calculate_metrics(df_split['n'], df_split['cmem_n_ans_str'])['overall'])\n",
    "\n",
    "\n",
    "zs_precision_avg = sum([rs['macro_precision'] for rs in zs_n_results])/len(zs_n_results)\n",
    "zs_recall_avg = sum([rs['macro_recall'] for rs in zs_n_results])/len(zs_n_results)\n",
    "zs_f1_avg = sum([rs['macro_f1'] for rs in zs_n_results])/len(zs_n_results)\n",
    "\n",
    "zscot_precision_avg = sum([rs['macro_precision'] for rs in zscot_n_results])/len(zscot_n_results)\n",
    "zscot_recall_avg = sum([rs['macro_recall'] for rs in zscot_n_results])/len(zscot_n_results)\n",
    "zscot_f1_avg = sum([rs['macro_f1'] for rs in zscot_n_results])/len(zscot_n_results)\n",
    "\n",
    "rag_precision_avg = sum([rs['macro_precision'] for rs in rag_n_results])/len(rag_n_results)\n",
    "rag_recall_avg = sum([rs['macro_recall'] for rs in rag_n_results])/len(rag_n_results)\n",
    "rag_f1_avg = sum([rs['macro_f1'] for rs in rag_n_results])/len(rag_n_results)\n",
    "\n",
    "\n",
    "x_axis = np.array(range(1, 11)) * 10\n",
    "\n",
    "memory_precision_cumulative = []\n",
    "memory_recall_cumulative = []\n",
    "memory_f1_cumulative = []\n",
    "devided_by = 0\n",
    "for run in range(total_run):\n",
    "    df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_n03_dynamic_test_{run}_outof_10runs.csv\")\n",
    "\n",
    "    for i in np.array(range(1, 11)): # memory (10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n",
    "        result = n03_calculate_metrics(df['n'], df[f'cmem_n_{i*10}reports_ans_str'])['overall']\n",
    "        if run == 0:\n",
    "            memory_precision_cumulative.append(result['macro_precision'])\n",
    "            memory_recall_cumulative.append(result['macro_recall'])\n",
    "            memory_f1_cumulative.append(result['macro_f1'])\n",
    "        else:\n",
    "            memory_precision_cumulative[i-1] += result['macro_precision']\n",
    "            memory_recall_cumulative[i-1] += result['macro_recall']\n",
    "            memory_f1_cumulative[i-1] += result['macro_f1']\n",
    "    devided_by += 1\n",
    "\n",
    "\n",
    "# average\n",
    "precision_avg = [p / devided_by for p in memory_precision_cumulative]\n",
    "recall_avg = [r / devided_by for r in memory_recall_cumulative]\n",
    "f1_avg = [f / devided_by for f in memory_f1_cumulative]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.plot(x_axis, precision_avg, label='Average KEPA Precision', color='blue', marker='o')\n",
    "plt.plot(x_axis, recall_avg, label='Average KEPA Recall', color='green', marker='o')\n",
    "plt.plot(x_axis, f1_avg, label='Average KEPA F1 Score', color='red')\n",
    "\n",
    "\n",
    "plt.axhline(y=zscot_precision_avg, color='blue', linestyle=':', label='ZSCOT Precision')\n",
    "plt.axhline(y=zscot_recall_avg, color='green', linestyle=':', label='ZSCOT Recall')\n",
    "plt.axhline(y=zscot_f1_avg, color='red', linestyle=':', label='ZSCOT F1 Score')\n",
    "\n",
    "plt.axhline(y=rag_precision_avg, color='blue', linestyle='--', label='RAG Precision')\n",
    "plt.axhline(y=rag_recall_avg, color='green', linestyle='--', label='RAG Recall')\n",
    "plt.axhline(y=rag_f1_avg, color='red', linestyle='--', label='RAG F1 Score')\n",
    "\n",
    "plt.text(x_axis[-1] + 2, zscot_precision_avg, f'{zscot_precision_avg:.3f}', fontsize=9, ha='left', va='center', color='blue')\n",
    "plt.text(x_axis[-1] + 2, zscot_recall_avg, f'{zscot_recall_avg:.3f}', fontsize=9, ha='left', va='center', color='green')\n",
    "plt.text(x_axis[-1] + 2, zscot_f1_avg, f'{zscot_f1_avg:.3f}', fontsize=9, ha='left', va='center', color='red')\n",
    "\n",
    "plt.xlabel('Number of Training Reports')\n",
    "plt.ylabel('Scores')\n",
    "# plt.title(f'The Average of 10 Results on 700 Test Reports (n03)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-run for Error cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key = \"empty\",\n",
    "                base_url = \"http://localhost:8000/v1\")\n",
    "    \n",
    "class TestingResponse(BaseModel):\n",
    "    predictedStage: str = Field(description=\"predicted cancer stage\")\n",
    "    reasoning: str = Field(description=\"reasoning to support predicted cancer stage\") \n",
    "\n",
    "testing_schema = TestingResponse.model_json_schema()\n",
    "\n",
    "def test_individual_report(dataset: pd.DataFrame, patient_filename: str, memory_tup: tuple, category = 'n'):\n",
    "    num, memory = memory_tup\n",
    "    report = dataset[dataset.patient_filename == patient_filename][\"text\"].values[0]\n",
    "\n",
    "    if category.lower()[0] == 'n':\n",
    "        prompt = testing_predict_prompt_n03.format(memory=memory, report=report)\n",
    "    else:\n",
    "        prompt = testing_predict_prompt_t14.format(memory=memory, report=report)\n",
    "    \n",
    "    prompt = system_instruction + \"\\n\" + prompt\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "        messages = messages,\n",
    "        extra_body = {\"guided_json\": testing_schema},\n",
    "        temperature = 0.1)\n",
    "    # response = json.loads(response.choices[0].message.content.replace(\"\\\\\", \"\\\\\\\\\"))\n",
    "    response = json.loads(response.choices[0].message.content)\n",
    "\n",
    "    dataset.loc[dataset[\"patient_filename\"] == patient_filename, f\"cmem_{category}_{num}reports_is_parsed\"] = True\n",
    "    dataset.loc[dataset[\"patient_filename\"] == patient_filename, f\"cmem_{category}_{num}reports_ans_str\"] = response[\"predictedStage\"]\n",
    "    dataset.loc[dataset[\"patient_filename\"] == patient_filename, f\"cmem_{category}_{num}reports_reasoning\"] = response[\"reasoning\"]\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T14\n",
    "for run in range(10):\n",
    "    print(f\"{run}th split\")\n",
    "\n",
    "    t_train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/t14_memory_dataset{run}.csv\")\n",
    "    memory_tup = []\n",
    "    for idx, row in t_train_df.iterrows():\n",
    "        memory_tup.append((idx+1,row['cmem_t_memory_str']))\n",
    "    memory_tup = memory_tup[9::10]\n",
    "\n",
    "    df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_t14_dynamic_test_{run}_outof_10runs.csv\")\n",
    "    for num, memory in memory_tup:\n",
    "        print(f\"{num}th memory\")\n",
    "        for idx in range(len(df)):     \n",
    "            patient_filename = df.loc[idx, \"patient_filename\"]\n",
    "            if not isinstance(df.loc[df[\"patient_filename\"] == patient_filename, f\"cmem_t_{num}reports_ans_str\"].values.item(), str):\n",
    "                print(idx) \n",
    "                print(\"before: \", df.loc[df[\"patient_filename\"] == patient_filename, f\"cmem_t_{num}reports_ans_str\"].values.item())\n",
    "                test_individual_report(df, patient_filename, (num, memory), 't')\n",
    "                print(\"after: \", df.loc[df[\"patient_filename\"] == patient_filename, f\"cmem_t_{num}reports_ans_str\"].values.item())\n",
    "                print(\"label: \", df.loc[df[\"patient_filename\"] == patient_filename, \"t\"].values.item())\n",
    "    \n",
    "    df.to_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_t14_dynamic_test_{run}_outof_10runs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N03\n",
    "for run in range(10):\n",
    "    print(f\"{run}th split\")\n",
    "\n",
    "    t_train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/n03_memory_dataset{run}.csv\")\n",
    "    memory_tup = []\n",
    "    for idx, row in t_train_df.iterrows():\n",
    "        memory_tup.append((idx+1,row['cmem_n_memory_str']))\n",
    "    memory_tup = memory_tup[9::10]\n",
    "\n",
    "    df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_n03_dynamic_test_{run}_outof_10runs.csv\")\n",
    "    for num, memory in memory_tup:\n",
    "        print(f\"{num}th memory\")\n",
    "        for idx in range(len(df)):     \n",
    "            patient_filename = df.loc[idx, \"patient_filename\"]\n",
    "            if not isinstance(df.loc[df[\"patient_filename\"] == patient_filename, f\"cmem_n_{num}reports_ans_str\"].values.item(), str):\n",
    "                print(idx) \n",
    "                print(\"before: \", df.loc[df[\"patient_filename\"] == patient_filename, f\"cmem_n_{num}reports_ans_str\"].values.item())\n",
    "                test_individual_report(df, patient_filename, (num, memory), 'n')\n",
    "                print(\"after: \", df.loc[df[\"patient_filename\"] == patient_filename, f\"cmem_n_{num}reports_ans_str\"].values.item())\n",
    "                print(\"label: \", df.loc[df[\"patient_filename\"] == patient_filename, \"n\"].values.item())\n",
    "    \n",
    "    df.to_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/0718_n03_dynamic_test_{run}_outof_10runs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Difference in Performance Based on the Order of Fields in the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = 6\n",
    "\n",
    "# test_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/0718_t14_dynamic_test_{run}_outof_10runs.csv\")\n",
    "# for i in np.array(range(1, 11)): # memory (10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n",
    "#     result = t14_calculate_metrics(test_df['t'], test_df[f'cmem_t_{i*10}reports_ans_str'])['overall']\n",
    "#     print(result)\n",
    "\n",
    "\n",
    "# test_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/0718_t14_dynamic_test_{run}_outof_10runs_revised.csv\")\n",
    "# for i in np.array(range(1, 11)): # memory (10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n",
    "#     if len(test_df[test_df[f\"cmem_t_{i*10}reports_is_parsed\"]==False]) > 0:\n",
    "#         print(len(test_df[test_df[f\"cmem_t_{i*10}reports_is_parsed\"]==False]))\n",
    "#     print(t14_calculate_metrics(test_df['t'], test_df[f'cmem_t_{i*10}reports_ans_str'])['overall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/0718_n03_dynamic_test_5_outof_10runs_reordered.csv\")\n",
    "# for i in np.array(range(1, 11)): # memory (10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n",
    "#     result = n03_calculate_metrics(n_df['n'], n_df[f'cmem_n_{i*10}reports_ans_str'])['overall']\n",
    "#     print(result)\n",
    "\n",
    "# n_df = pd.read_csv(\"/home/yl3427/cylab/selfCorrectionAgent/0718_n03_dynamic_test_5_outof_10runs.csv\")\n",
    "# for i in np.array(range(1, 11)): # memory (10, 20, 30, 40, 50, 60, 70, 80, 90, 100)\n",
    "#     result = n03_calculate_metrics(n_df['n'], n_df[f'cmem_n_{i*10}reports_ans_str'])['overall']\n",
    "#     print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Memory length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual memory string length for T14\n",
    "\n",
    "for i in range(10):\n",
    "    train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/t14_memory_dataset{i}.csv\")\n",
    "    x_indices = []\n",
    "    y_str_length_mem = []\n",
    "    y_str_length_rules = []\n",
    " \n",
    "    for idx, row in train_df.iterrows():\n",
    "        x_indices.append(idx+1)\n",
    "        y_str_length_mem.append(len(row['cmem_t_memory_str']))\n",
    "        y_str_length_rules.append(len(row['cmem_t_rules_str']))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    plt.plot(x_indices, y_str_length_mem, label='Memory String Length', color='blue', marker='o')\n",
    "    plt.plot(x_indices, y_str_length_rules, label='Rules String Length', color='red', marker='o')\n",
    "\n",
    "    plt.xlabel(f'Index of Memory Dataset (t14_memory_dataset{i}.csv)')\n",
    "    plt.ylabel('Length')\n",
    "    # plt.title(f'Length of Memory and Rules')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average memory string length for T14\n",
    "y_str_length_mem_arr = np.array([0]*100)\n",
    "y_str_length_rules_arr = np.array([0]*100)\n",
    "x_indices = np.array(range(1, 101))\n",
    "\n",
    "for i in range(10):\n",
    "    train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/t14_memory_dataset{i}.csv\")\n",
    "\n",
    "    for idx, row in train_df.iterrows():\n",
    "        y_str_length_mem_arr[idx] += len(row['cmem_t_memory_str'])\n",
    "        y_str_length_rules_arr[idx] += len(row['cmem_t_rules_str']) \n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.plot(x_indices, y_str_length_mem_arr/10, label='Threshold 80', color='blue', marker='o')\n",
    "plt.plot(x_indices, y_str_length_rules_arr/10, label='Threshold 0', color='red', marker='o')\n",
    "\n",
    "plt.xlabel(f'Number of Training Reports (T14)')\n",
    "plt.ylabel('Average Length of Memory')\n",
    "# plt.title(f'Length of Memory and Rules')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual number of rules in memory for T14\n",
    "for i in range(10):\n",
    "    train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/t14_memory_dataset{i}.csv\")\n",
    "    x_indices = []\n",
    "\n",
    "    y_num_rules_mem = []\n",
    "    y_num_rules_rules = []\n",
    "    for idx, row in train_df.iterrows():\n",
    "        x_indices.append(idx+1)\n",
    "        y_num_rules_mem.append(len(row['cmem_t_memory_str'].split(\"\\n\")))\n",
    "        y_num_rules_rules.append(len(row['cmem_t_rules_str'].split(\"\\n\")))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    plt.plot(x_indices, y_num_rules_mem, label='Memory Num Rules', color='blue', marker='o')\n",
    "    plt.plot(x_indices, y_num_rules_rules, label='Rules Num Rules', color='red', marker='o')\n",
    "\n",
    "    plt.xlabel(f'Index of Memory Dataset (t14_memory_dataset{i}.csv)')\n",
    "    plt.ylabel('Number')\n",
    "    plt.title(f'Number of Rules')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    max_y = max(max(y_num_rules_mem), max(y_num_rules_rules))\n",
    "    plt.yticks(range(0, int(max_y) + 1))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average number of rules in memory for T14\n",
    "y_num_rules_mem_arr = np.array([0]*100)\n",
    "y_num_rules_rules_arr = np.array([0]*100)\n",
    "x_indices = np.array(range(1, 101))\n",
    "\n",
    "for i in range(10):\n",
    "    train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/t14_memory_dataset{i}.csv\")\n",
    "\n",
    "    for idx, row in train_df.iterrows():\n",
    "        y_num_rules_mem_arr[idx] += len(row['cmem_t_memory_str'].split(\"\\n\"))\n",
    "        y_num_rules_rules_arr[idx] += len(row['cmem_t_rules_str'].split(\"\\n\"))\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.plot(x_indices, y_num_rules_mem_arr/10, label='Threshold 80', color='blue', marker='o')\n",
    "plt.plot(x_indices, y_num_rules_rules_arr/10, label='Threshold 0', color='red', marker='o')\n",
    "\n",
    "plt.xlabel(f'Number of Training Reports')\n",
    "plt.ylabel('Average Number of Rules')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual memory string length for N03\n",
    "for i in range(10):\n",
    "    train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/n03_memory_dataset{i}.csv\")\n",
    "    x_indices = []\n",
    "    y_str_length_mem = []\n",
    "    y_str_length_rules = []\n",
    " \n",
    "    for idx, row in train_df.iterrows():\n",
    "        x_indices.append(idx+1)\n",
    "        y_str_length_mem.append(len(row['cmem_n_memory_str']))\n",
    "        y_str_length_rules.append(len(row['cmem_n_rules_str']))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    plt.plot(x_indices, y_str_length_mem, label='Memory String Length', color='blue', marker='o')\n",
    "    plt.plot(x_indices, y_str_length_rules, label='Rules String Length', color='red', marker='o')\n",
    "\n",
    "    plt.xlabel(f'Index of Memory Dataset (n03_memory_dataset{i}.csv)')\n",
    "    plt.ylabel('Length')\n",
    "    # plt.title(f'Length of Memory and Rules')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average memory string length for N03\n",
    "y_str_length_mem_arr = np.array([0]*100)\n",
    "y_str_length_rules_arr = np.array([0]*100)\n",
    "x_indices = np.array(range(1, 101))\n",
    "\n",
    "for i in range(10):\n",
    "    train_df = pd.read_csv(f\"/home/yl3427/cylab/selfCorrectionAgent/result/n03_memory_dataset{i}.csv\")\n",
    "\n",
    "    for idx, row in train_df.iterrows():\n",
    "        y_str_length_mem_arr[idx] += len(row['cmem_n_memory_str'])\n",
    "        y_str_length_rules_arr[idx] += len(row['cmem_n_rules_str']) \n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.plot(x_indices, y_str_length_mem_arr/10, label='Threshold 80', color='blue', marker='o')\n",
    "plt.plot(x_indices, y_str_length_rules_arr/10, label='Threshold 0', color='red', marker='o')\n",
    "\n",
    "plt.xlabel(f'Number of Training Reports (N03)')\n",
    "plt.ylabel('Average Length of Memory')\n",
    "# plt.title(f'Length of Memory and Rules')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create format instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TrainingResponse(BaseModel):\n",
    "#     reasoning: str = Field(description=\"reasoning to support predicted cancer stage\")\n",
    "#     predictedStage: str = Field(description=\"predicted cancer stage\")\n",
    "#     rules: List[str] = Field(description=\"list of rules\") \n",
    "\n",
    "# class TestingResponse(BaseModel):\n",
    "#     reasoning: str = Field(description=\"reasoning to support predicted cancer stage\") \n",
    "#     predictedStage: str = Field(description=\"predicted cancer stage\")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(TrainingResponse.model_json_schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = PydanticOutputParser(pydantic_object=TestingResponse)\n",
    "# format_instruction=parser.get_format_instructions()\n",
    "# print(type(format_instruction))\n",
    "# print(format_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res=TestingResponse.model_validate_json('{\\n  \"predictedStage\": \"T2\",\\n  \"reasoning\": \"The largest dimension of the tumor is 3.7 cm, which falls within the range for T2 (greater than 2 cm but not greater than 5 cm).\"\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vendiagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3\n",
    "\n",
    "# Define the subset sizes again, considering the total values for each set\n",
    "subsets = {'100': 7, '010': 1, '001': 14, '111': 49, '110': 0, '101': 2}\n",
    "\n",
    "# Re-create the Venn diagram with adjustments\n",
    "plt.figure(figsize=(8, 8))\n",
    "venn = venn3(subsets=subsets, set_labels=('kepa', 'zscot', 'label'))\n",
    "\n",
    "# Adjust circle sizes if necessary manually (note: matplotlib_venn doesn't always allow this directly)\n",
    "# So we can only guide by the correct inputs\n",
    "\n",
    "plt.title(\"Adjusted Venn Diagram\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfCorrection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

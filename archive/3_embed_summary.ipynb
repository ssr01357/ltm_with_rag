{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics_summary import t14_performance_report, n03_performance_report, m01_performance_report, _boostrap_resampling_report\n",
    "from huggingface_hub import InferenceClient\n",
    "import chromadb\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.utils import resample\n",
    "from scipy import stats\n",
    "import tiktoken\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "if not load_dotenv(find_dotenv()):\n",
    "    raise Exception(\"Failed to load .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize collection instance in Chroma database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Initialize the helper for OpenAI's embedding API\n",
    "and also initialize Chroma's client and select the target collection\n",
    "\"\"\"\n",
    "\n",
    "# text-embedding-3-small is better than text-embedding-ada-002\n",
    "# the best-perfoming model is text-embedding-3-small (we can consider it later when the cost is allowed.)\n",
    "\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=os.getenv('OPENAI_API_KEY'),\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )\n",
    "client = chromadb.PersistentClient(\"/secure/shared_data/tcga_path_reports/chroma_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_collection(\"luad-summary-emb-t14-test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter out correct summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"/secure/shared_data/rag_tnm_results/summary/summary\"\n",
    "file_names = [\"BRCA_N03_testing.csv\", \"BRCA_T14_testing.csv\", \"LUAD_N03_testing.csv\", \"LUAD_T14_testing.csv\",\n",
    "    \"BRCA_N03_training.csv\", \"BRCA_T14_training.csv\", \"LUAD_N03_training.csv\", \"LUAD_T14_training.csv\"]\n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(file_dir, \"withSummary_\"+file_name)\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    col_lst = [\"zs_ans_from_text\", \"zs_ans_from_abstract\", \"zs_ans_from_extract\"]\n",
    "\n",
    "    if \"m01\" in re.search(r'[M|N|T]\\d\\d', file_name).group().lower():\n",
    "        print(\"M\")\n",
    "        _, df = m01_performance_report(df, ans_cols=col_lst)\n",
    "    elif \"n03\" in re.search(r'[M|N|T]\\d\\d', file_name).group().lower():\n",
    "        print(\"N\")\n",
    "        _, df = n03_performance_report(df, ans_cols=col_lst)\n",
    "    elif \"t14\" in re.search(r'[M|N|T]\\d\\d', file_name).group().lower():\n",
    "        print(\"T\")\n",
    "        _, df = t14_performance_report(df, ans_cols=col_lst)\n",
    "\n",
    "    df.to_csv(file_path, index=False)\n",
    " \n",
    "\n",
    "for file_name in file_names:\n",
    "    file_path = os.path.join(file_dir, \"withSummary_\"+file_name)   \n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    if \"n03\" in re.search(r'[M|N|T]\\d\\d', file_name).group().lower():\n",
    "        label = \"n\"\n",
    "    elif \"t14\" in re.search(r'[M|N|T]\\d\\d', file_name).group().lower():\n",
    "        label = \"t\"\n",
    "\n",
    "    valid_df = df[df[\"0_Has_Valid_Prediction\"] & df[\"1_Has_Valid_Prediction\"]]\n",
    "    good_df = valid_df[(valid_df[\"0_coded_pred\"] == valid_df[\"1_coded_pred\"]) & (valid_df[\"1_coded_pred\"] == valid_df[label])]\n",
    "    good_df.to_csv(os.path.join(file_dir, \"OnlyCorrectSummary_\"+file_name), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"/secure/shared_data/rag_tnm_results/summary\"\n",
    "file_name = 'withSummary_merged_df.csv'\n",
    "\n",
    "file_path = os.path.join(file_dir, \"withInference_\"+file_name)\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df[\"zs_ans_from_text_n\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on full summary\n",
    "file_dir = \"/secure/shared_data/rag_tnm_results/summary\"\n",
    "file_name = 'withSummary_merged_df.csv'\n",
    "\n",
    "file_path = os.path.join(file_dir, \"withInference_\"+file_name)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "col_lst_t = [\"zs_ans_from_text_t\", \"zs_ans_from_abstract_t\", \"zs_ans_from_extract_t\"]\n",
    "_, df = t14_performance_report(df, ans_cols=col_lst_t)\n",
    "\n",
    "col_lst_n = [\"zs_ans_from_text_n\", \"zs_ans_from_abstract_n\", \"zs_ans_from_extract_n\"]\n",
    "_, df = n03_performance_report(df, ans_cols=col_lst_n)\n",
    "\n",
    "print(\"Now saving...\")\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_t_df = df[df[\"0_Has_Valid_Prediction_t\"] & df[\"1_Has_Valid_Prediction_t\"]]\n",
    "# good_t_df = valid_t_df[(valid_t_df[\"0_coded_pred_t\"] == valid_t_df[\"1_coded_pred_t\"]) & (valid_t_df[\"1_coded_pred_t\"] == valid_t_df['t'])]\n",
    "# good_t_df.to_csv(os.path.join(file_dir, \"OnlyCorrectSummary_T_\"+file_name), index=False)\n",
    "\n",
    "\n",
    "\n",
    "# valid_n_df = df[df[\"0_Has_Valid_Prediction_n\"] & df[\"1_Has_Valid_Prediction_n\"]]\n",
    "# good_n_df = valid_n_df[(valid_n_df[\"0_coded_pred_n\"] == valid_n_df[\"1_coded_pred_n\"]) & (valid_n_df[\"1_coded_pred_n\"] == valid_n_df['n'])]\n",
    "# good_n_df.to_csv(os.path.join(file_dir, \"OnlyCorrectSummary_N_\"+file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/yl3427/cylab/yewon_data/Updated_withSummary_merged_df.csv\")\n",
    "print(df.columns)\n",
    "df.drop(columns=['is_goodsum_t', 'is_goodsum_n'], inplace=True)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"is_goodsum_t\"] = (df[\"0_Has_Valid_Prediction_t\"] & df[\"2_Has_Valid_Prediction_t\"]) & \\\n",
    "#                   (df[\"0_coded_pred_t\"] == df[\"2_coded_pred_t\"]) & \\\n",
    "#                   (df[\"2_coded_pred_t\"] == df['t'])\n",
    "\n",
    "# df[\"is_goodsum_n\"] = (df[\"0_Has_Valid_Prediction_n\"] & df[\"2_Has_Valid_Prediction_n\"]) & \\\n",
    "#                   (df[\"0_coded_pred_n\"] == df[\"2_coded_pred_n\"]) & \\\n",
    "#                   (df[\"2_coded_pred_n\"] == df['n'])\n",
    "\n",
    "df[\"is_goodsum_t\"] = (df[\"2_coded_pred_t\"] == df['t'])\n",
    "\n",
    "df[\"is_goodsum_n\"] = (df[\"2_coded_pred_n\"] == df['n'])\n",
    "\n",
    "df.to_csv(os.path.join(\"/home/yl3427/cylab/yewon_data\", \"usingExtract_fs_merged_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"is_goodsum_t\"]]['t'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed documents into representations and store into the collection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the reports, embed them, save them in the ChromaDB's collection\n",
    "\"\"\"\n",
    "# prompt_for_abstract,prompt_for_extract,abstractive_summary,extractive_summary,ans_from_text,ans_from_abstract,ans_from_extract,0_Has_Valid_Prediction,0_coded_pred,1_Has_Valid_Prediction,1_coded_pred,2_Has_Valid_Prediction,2_coded_pred\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "def embed_reports_in_chroma(report_df, collection, label_name = \"t\"):\n",
    "    \n",
    "    pbar = tqdm(total=report_df.shape[0])\n",
    "\n",
    "    for _, report in report_df.iterrows():\n",
    "        report_patient_filename = report[\"patient_filename\"]\n",
    "        report_label = report[label_name]\n",
    "        report_text = report[\"abstractive_summary\"]\n",
    "        report_length_cl100k_base = num_tokens_from_string(report_text, \"cl100k_base\")\n",
    "\n",
    "        collection.add(\n",
    "            embeddings=openai_ef([report_text])[0],\n",
    "            metadatas={\"patient_filename\": report_patient_filename, label_name: report_label, \"report_length_cl100k_base\": report_length_cl100k_base},\n",
    "            documents=report_text,\n",
    "            ids=report_patient_filename\n",
    "        )\n",
    "        pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dir = \"/home/yl3427/rag_tnm2/summary/data/summary\"\n",
    "# file_names = [\"BRCA_N03_testing.csv\", \"BRCA_T14_testing.csv\", \"LUAD_N03_testing.csv\", \"LUAD_T14_testing.csv\",\n",
    "#     \"BRCA_N03_training.csv\", \"BRCA_T14_training.csv\", \"LUAD_N03_training.csv\", \"LUAD_T14_training.csv\"]\n",
    "\n",
    "# for file_name in file_names:\n",
    "#     file_name = \"OnlyCorrectSummary_\"+file_name\n",
    "#     file_path = os.path.join(file_dir, file_name)\n",
    "#     collection_name = file_name.replace(\".csv\", \"_emb\")\n",
    "\n",
    "#     if \"n03\" in re.search(r'[M|N|T]\\d\\d', file_name).group().lower():\n",
    "#         label = \"n\"\n",
    "#     elif \"t14\" in re.search(r'[M|N|T]\\d\\d', file_name).group().lower():\n",
    "#         label = \"t\"\n",
    "        \n",
    "#     collection = client.get_or_create_collection(collection_name)\n",
    "#     df = pd.read_csv(file_path)\n",
    "#     embed_reports_in_chroma(df, collection, label_name = label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "client = chromadb.Client()\n",
    "# client = chromadb.PersistentClient(\n",
    "#     path=\"test\",\n",
    "#     settings=Settings(allow_reset=True),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB > Collections > Documents / Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection1 = client.create_collection(name = \"my_collection1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection1.add(\n",
    "    documents = [\"This is a test document\",\"This is another test document\"],\n",
    "    metadatas = [{\"source\": \"source1\", \"language\": \"en\"}, {\"source\": \"source2\"}],\n",
    "    ids = [\"id1\", \"id2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods that can be run on clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(id=c62c4890-8ce2-45bf-b1b9-f7ec040db390, name=my_collection1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# methods can be run on clients\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an existing collection\n",
    "collection1 = client.get_collection(\"my_collection1\")\n",
    "collection1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection or create it if it doesn't exist\n",
    "collection2 = client.get_or_create_collection(\"my_collection2\")\n",
    "collection2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete a collection\n",
    "client.delete_collection(\"my_collection2\")\n",
    "client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility methods\n",
    "\n",
    "# heartbeats: returns a nanosecond heartbeat. Useful for making sure the client remains connected.\n",
    "client.heartbeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.reset() # persistent client only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods that can be run on collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# couunt the number of documents in a collection\n",
    "collection1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [],\n",
       " 'embeddings': [],\n",
       " 'metadatas': [],\n",
       " 'documents': [],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['embeddings', 'documents', 'metadatas']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get items from a collection\n",
    "collection1.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "# 여기서는 embedding이 없어서 None이 나옴. 따로 가지고 있다면 넣어줄 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new items to a collection\n",
    "# one at a time\n",
    "collection1.add(\n",
    "    embeddings = [[1.0],[4]],\n",
    "    documents = [\"This is document 3\", \"This is document 4\"],\n",
    "    metadatas = [{\"source\": \"source3\", \"language\": \"en\"}, {\"source\": \"source4\"}],\n",
    "    ids = [\"id3\", \"id4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id3', 'id4'],\n",
       " 'embeddings': [[1.0], [4.0]],\n",
       " 'metadatas': [{'language': 'en', 'source': 'source3'}, {'source': 'source4'}],\n",
       " 'documents': ['This is document 3', 'This is document 4'],\n",
       " 'uris': None,\n",
       " 'data': None,\n",
       " 'included': ['embeddings', 'documents', 'metadatas']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection1.get(include=['embeddings', 'documents', 'metadatas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsert\n",
    "collection1.upsert(\n",
    "    documents = [\"doc3\", \"This is document 4\"],\n",
    "    metadatas = [{\"source\": \"source3\", \"language\": \"en\"}, {\"source\": \"source4\"}],\n",
    "    ids = [\"id3\", \"id4\"])\n",
    "\n",
    "collection1.get(include=['embeddings', 'documents', 'metadatas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection1.peek()['embeddings'][1] # first five items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl3427/miniconda3/envs/llm_env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "import pandas as pd\n",
    "\n",
    "# def clean_extra_whitespace_within_paragraphs(text):\n",
    "#     return re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "# def group_broken_paragraphs(text):\n",
    "#     text = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", text)\n",
    "#     # text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
    "#     return text\n",
    "\n",
    "# doc = pymupdf.open(\"/home/yl3427/cylab/rag_tnm/selfCorrectionAgent/ajcc_7thed_cancer_staging_manual.pdf\") # open a document\n",
    "# text = \"\"\n",
    "\n",
    "# for page in doc: # iterate the document pages\n",
    "#     text += page.get_text()\n",
    "\n",
    "# text = clean_extra_whitespace_within_paragraphs(text) # clean extra whitespace\n",
    "# text = group_broken_paragraphs(text) # group broken paragraphs\n",
    "\n",
    "def load_pdf(files=\"/home/yl3427/cylab/rag_tnm/selfCorrectionAgent/ajcc_7thed_cancer_staging_manual.pdf\"):\n",
    "    if not isinstance(files, list):\n",
    "        files = [files]  \n",
    "\n",
    "    documents = []\n",
    "    for file_path in files:\n",
    "        doc = pymupdf.open(file_path)\n",
    "        text = \"\"\n",
    "        \n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "\n",
    "        text = group_broken_paragraphs(text)\n",
    "        text = clean_extra_whitespace_within_paragraphs(text)\n",
    "\n",
    "        document = Document(\n",
    "            page_content=text,\n",
    "            metadata={\"source\": file_path}\n",
    "        )\n",
    "        documents.append(document)\n",
    "\n",
    "\n",
    "    return documents\n",
    "\n",
    "def clean_extra_whitespace_within_paragraphs(text):\n",
    "    return re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "def group_broken_paragraphs(text):\n",
    "    text = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", text)\n",
    "    # text = re.sub(r\"\\n{2,}\", \"\\n\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SlidingWindowCache' from 'transformers.cache_utils' (/home/yl3427/miniconda3/envs/llm_env/lib/python3.10/site-packages/transformers/cache_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m passages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSince you\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mre reading this, you are probably someone from a judo background or someone who is just wondering how judo techniques can be applied under wrestling rules. So without further ado, let\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms get to the question. Are Judo throws allowed in wrestling? Yes, judo throws are allowed in freestyle and folkstyle wrestling. You only need to be careful to follow the slam rules when executing judo throws. In wrestling, a slam is lifting and returning an opponent to the mat with unnecessary force.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are the basic steps to becoming a radiologic technologist in Michigan:Earn a high school diploma. As with most careers in health care, a high school education is the first step to finding entry-level employment. Taking classes in math and science, such as anatomy, biology, chemistry, physiology, and physics, can help prepare students for their college studies and future careers.Earn an associate degree. Entry-level radiologic positions typically require at least an Associate of Applied Science. Before enrolling in one of these degree programs, students should make sure it has been properly accredited by the Joint Review Committee on Education in Radiologic Technology (JRCERT).Get licensed or certified in the state of Michigan.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m ]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# load model with tokenizer\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnvidia/NV-Embed-v2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mmax_seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32768\u001b[39m\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mpadding_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_env/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:294\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data)\u001b[0m\n\u001b[1;32m    285\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[1;32m    288\u001b[0m     model_name_or_path,\n\u001b[1;32m    289\u001b[0m     token,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    292\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    293\u001b[0m ):\n\u001b[0;32m--> 294\u001b[0m     modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_sbert_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[1;32m    307\u001b[0m         model_name_or_path,\n\u001b[1;32m    308\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    315\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[1;32m    316\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_env/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:1647\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;66;03m# Try to initialize the module with a lot of kwargs, but only if the module supports them\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;66;03m# Otherwise we fall back to the load method\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1647\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1649\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class\u001b[38;5;241m.\u001b[39mload(model_name_or_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_env/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:56\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, tokenizer_args, config_args, cache_dir, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[1;32m     53\u001b[0m     config_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     55\u001b[0m config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_args, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir)\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_seq_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tokenizer_args:\n\u001b[1;32m     59\u001b[0m     tokenizer_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_max_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m max_seq_length\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_env/lib/python3.10/site-packages/sentence_transformers/models/Transformer.py:87\u001b[0m, in \u001b[0;36mTransformer._load_model\u001b[0;34m(self, model_name_or_path, config, cache_dir, **model_args)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_mt5_model(model_name_or_path, config, cache_dir, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_args)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_env/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:548\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_remote_code \u001b[38;5;129;01mand\u001b[39;00m trust_remote_code:\n\u001b[1;32m    547\u001b[0m     class_ref \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mauto_map[\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m]\n\u001b[0;32m--> 548\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[43mget_class_from_dynamic_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m     _ \u001b[38;5;241m=\u001b[39m hub_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(pretrained_model_name_or_path):\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_env/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:500\u001b[0m, in \u001b[0;36mget_class_from_dynamic_module\u001b[0;34m(class_reference, pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, repo_type, code_revision, **kwargs)\u001b[0m\n\u001b[1;32m    497\u001b[0m module_file, class_name \u001b[38;5;241m=\u001b[39m class_reference\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m code_revision \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m pretrained_model_name_or_path \u001b[38;5;241m==\u001b[39m repo_id:\n\u001b[0;32m--> 500\u001b[0m     code_revision \u001b[38;5;241m=\u001b[39m revision\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# And lastly we get the class inside our newly created module\u001b[39;00m\n\u001b[1;32m    502\u001b[0m final_module \u001b[38;5;241m=\u001b[39m get_cached_module_file(\n\u001b[1;32m    503\u001b[0m     repo_id,\n\u001b[1;32m    504\u001b[0m     module_file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    512\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    513\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_env/lib/python3.10/site-packages/transformers/dynamic_module_utils.py:200\u001b[0m, in \u001b[0;36mget_class_in_module\u001b[0;34m(class_name, module_path)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_class_in_module\u001b[39m(class_name: \u001b[38;5;28mstr\u001b[39m, module_path: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m typing\u001b[38;5;241m.\u001b[39mType:\n\u001b[1;32m    191\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    Import a module on the cache directory for modules and extract a class from it.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m        class_name (`str`): The name of the class to import.\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;124;03m        module_path (`str` or `os.PathLike`): The path to the module to import.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m        `typing.Type`: The class looked for.\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(module_path)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_env/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/nvidia/NV-Embed-v2/26db444e203771ea231d32a795344655e1119d40/modeling_nvembed.py:11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmistral\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_mistral\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MISTRAL_INPUTS_DOCSTRING\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModelOutputWithPast\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _prepare_4d_attention_mask, _prepare_4d_attention_mask_for_sdpa\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_env/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ACT2FN\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cache, DynamicCache, SlidingWindowCache, StaticCache\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AttentionMaskConverter\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     34\u001b[0m     BaseModelOutputWithPast,\n\u001b[1;32m     35\u001b[0m     CausalLMOutputWithPast,\n\u001b[1;32m     36\u001b[0m     SequenceClassifierOutputWithPast,\n\u001b[1;32m     37\u001b[0m     TokenClassifierOutput,\n\u001b[1;32m     38\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SlidingWindowCache' from 'transformers.cache_utils' (/home/yl3427/miniconda3/envs/llm_env/lib/python3.10/site-packages/transformers/cache_utils.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Each query needs to be accompanied by an corresponding instruction describing the task.\n",
    "task_name_to_instruct = {\"example\": \"Given a question, retrieve passages that answer the question\",}\n",
    "\n",
    "query_prefix = \"Instruct: \"+task_name_to_instruct[\"example\"]+\"\\nQuery: \"\n",
    "queries = [\n",
    "    'are judo throws allowed in wrestling?', \n",
    "    'how to become a radiology technician in michigan?'\n",
    "    ]\n",
    "\n",
    "# No instruction needed for retrieval passages\n",
    "passages = [\n",
    "    \"Since you're reading this, you are probably someone from a judo background or someone who is just wondering how judo techniques can be applied under wrestling rules. So without further ado, let's get to the question. Are Judo throws allowed in wrestling? Yes, judo throws are allowed in freestyle and folkstyle wrestling. You only need to be careful to follow the slam rules when executing judo throws. In wrestling, a slam is lifting and returning an opponent to the mat with unnecessary force.\",\n",
    "    \"Below are the basic steps to becoming a radiologic technologist in Michigan:Earn a high school diploma. As with most careers in health care, a high school education is the first step to finding entry-level employment. Taking classes in math and science, such as anatomy, biology, chemistry, physiology, and physics, can help prepare students for their college studies and future careers.Earn an associate degree. Entry-level radiologic positions typically require at least an Associate of Applied Science. Before enrolling in one of these degree programs, students should make sure it has been properly accredited by the Joint Review Committee on Education in Radiologic Technology (JRCERT).Get licensed or certified in the state of Michigan.\"\n",
    "]\n",
    "\n",
    "# load model with tokenizer\n",
    "model = SentenceTransformer('nvidia/NV-Embed-v2', trust_remote_code=True)\n",
    "model.max_seq_length = 32768\n",
    "model.tokenizer.padding_side=\"right\"\n",
    "\n",
    "def add_eos(input_examples):\n",
    "  input_examples = [input_example + model.tokenizer.eos_token for input_example in input_examples]\n",
    "  return input_examples\n",
    "\n",
    "# get the embeddings\n",
    "batch_size = 2\n",
    "query_embeddings = model.encode(add_eos(queries), batch_size=batch_size, prompt=query_prefix, normalize_embeddings=True)\n",
    "passage_embeddings = model.encode(add_eos(passages), batch_size=batch_size, normalize_embeddings=True)\n",
    "\n",
    "scores = (query_embeddings @ passage_embeddings.T) * 100\n",
    "print(scores.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_NAME = 'BAAI/bge-large-en-v1.5'\n",
    "\n",
    "def plot_docs_tokens(docs_processed, EMBEDDING_MODEL_NAME):\n",
    "\n",
    "    print(f\"Model's maximum sequence length: {SentenceTransformer(EMBEDDING_MODEL_NAME).max_seq_length}\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_NAME)\n",
    "    lengths = [len(tokenizer.encode(doc.page_content)) for doc in docs_processed]\n",
    "\n",
    "    print(f\"Maximum sequence length in chunks: {max(lengths)}\")\n",
    "    fig = pd.Series(lengths).hist()\n",
    "    plt.title(\"Distribution of document lengths in the knowledge base (in count of tokens)\")\n",
    "    plt.show()\n",
    "\n",
    "def split_documents(\n",
    "    chunk_size: int,\n",
    "    knowledge_base,\n",
    "    tokenizer_name= EMBEDDING_MODEL_NAME,\n",
    "):\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
    "        separators = [\"\\n\\n\", \"\\n\", '(?<=[.?\"\\s])\\s+', \" \"],\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name),\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=0,\n",
    "        add_start_index=True,\n",
    "        strip_whitespace=True,\n",
    "        is_separator_regex=True\n",
    "    )\n",
    "\n",
    "    docs_processed = (text_splitter.split_documents([doc]) for doc in knowledge_base)\n",
    "\n",
    "    unique_texts = set()\n",
    "    docs_processed_unique = []\n",
    "    for doc_chunk in docs_processed:\n",
    "        for doc in doc_chunk:\n",
    "            if doc.page_content not in unique_texts:\n",
    "                unique_texts.add(doc.page_content)\n",
    "                docs_processed_unique.append(doc)\n",
    "\n",
    "    return docs_processed_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl3427/miniconda3/envs/llm_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1087 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "docs_processed = split_documents(\n",
    "    chunk_size = 512, \n",
    "    knowledge_base = documents,\n",
    "    tokenizer_name = EMBEDDING_MODEL_NAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's maximum sequence length: 512\n",
      "Maximum sequence length in chunks: 508\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_docs_tokens(docs_processed, EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 93\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chunks: {len(docs_processed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embedding_model(\n",
    "    model_name = \"BAAI/bge-large-en-v1.5\",\n",
    "    device = \"cuda\"\n",
    ") -> HuggingFaceBgeEmbeddings:\n",
    "    \n",
    "    model_kwargs = {\"device\": device}\n",
    "    encode_kwargs = {\"normalize_embeddings\": True}  # For cosine similarity computation\n",
    "\n",
    "    embedding_model = HuggingFaceBgeEmbeddings(\n",
    "        model_name=model_name,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs,\n",
    "    )\n",
    "    \n",
    "    return embedding_model\n",
    "\n",
    "\n",
    "def embed_docs_in_chroma(docs, collection):\n",
    "    \n",
    "    pbar = tqdm(total=len(docs))\n",
    "\n",
    "    for doc in docs:\n",
    "        id = doc.metadata[\"start_index\"]\n",
    "        doc_text = doc.page_content\n",
    "        collection.add(\n",
    "            embeddings=openai_ef([doc_text])[0],\n",
    "            metadatas={},\n",
    "            documents=doc_text,\n",
    "            ids=id\n",
    "        )\n",
    "        pbar.update(1)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yl3427/miniconda3/envs/llm_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HuggingFaceBgeEmbeddings' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m load_embedding_model()\n\u001b[0;32m----> 2\u001b[0m \u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a test sentence.\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/llm_env/lib/python3.10/site-packages/pydantic/main.py:853\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[0;32m--> 853\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HuggingFaceBgeEmbeddings' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "embedding_model = load_embedding_model()\n",
    "embedding_model.encode([\"This is a test sentence.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(id=557f5b31-a2e6-41f7-9a8f-6dc357cec51c, name=brca)\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "client = chromadb.Client()\n",
    "\n",
    "brca_collection = client.create_collection(name = \"brca\", metadata={\"hnsw:space\": \"cosine\"})\n",
    "print(brca_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection(id=557f5b31-a2e6-41f7-9a8f-6dc357cec51c, name=brca_collection)\n"
     ]
    }
   ],
   "source": [
    "brca_collection.modify(name=\"brca_collection\")\n",
    "print(brca_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hnsw:space': 'cosine'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brca_collection.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding raw documents\n",
    "brca_collection.add(\n",
    "    documents = [\n",
    "        \"This is a test document\",\n",
    "        \"This is another test document\"\n",
    "    ],\n",
    "    metadatas = [\n",
    "        {\"source\": \"source1\", \"language\": \"en\"},\n",
    "        {\"source\": \"source2\"}\n",
    "    ],\n",
    "    ids = [\"id1\", \"id2\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cancer-staging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
